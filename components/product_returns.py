"""
äº§å“æ”¶ç›Šç‡è®¡ç®—ï¼ˆç®€åŒ–ç‰ˆï¼‰
"""
import streamlit as st
import pandas as pd
import os
import glob
from datetime import datetime, timedelta


def get_latest_holding_files_with_total_assets():
    """è·å–åŒ…å«æ€»èµ„äº§çš„æœ€æ–°æŒä»“æ–‡ä»¶"""
    base_path = r"C:\shared_data\å®ç›˜\äº¤æ˜“æ•°æ®å®šé¢‘å¯¼å‡º"

    if not os.path.exists(base_path):
        return []

    # è·å–æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹å¹¶æ’åº
    date_folders = [f for f in os.listdir(base_path)
                    if f.isdigit() and len(f) == 8 and os.path.isdir(os.path.join(base_path, f))]

    all_files = []
    for date_folder in sorted(date_folders, reverse=True)[:3]:  # å–æœ€è¿‘3å¤©ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°ä¸åŒæ—¥æœŸ
        date_folder_path = os.path.join(base_path, date_folder)

        for root, dirs, files in os.walk(date_folder_path):
            for file in files:
                # è¿™ä¸ªå‡½æ•°ä¸»è¦ç”¨äºå®ç›˜æ•°æ®ï¼Œä½†å¦‚æœéœ€è¦æ”¯æŒä»¿çœŸï¼Œå¯ä»¥æ·»åŠ 
                if file.startswith("å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º") and (file.endswith('.xlsx') or file.endswith('.csv')):
                    file_path = os.path.join(root, file)

                    # è§£ææ—¶é—´
                    try:
                        filename = os.path.basename(file_path)
                        name_part = filename.replace('å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º_', '').replace('å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º-', '')
                        parts = name_part.split('_')
                        if len(parts) >= 2:
                            datetime_part = parts[-1]
                            if '-' in datetime_part:
                                date_time = datetime_part.replace('.xlsx', '').replace('.csv', '')
                                timestamp = datetime.strptime(date_time, "%Y%m%d-%H%M%S")

                                all_files.append({
                                    'file_path': file_path,
                                    'timestamp': timestamp,
                                    'date': date_folder,
                                    'filename': filename
                                })
                    except:
                        continue

    return sorted(all_files, key=lambda x: x['timestamp'], reverse=True)


def read_total_assets_from_holding_file(file_path):
    """ä»èµ„äº§æ–‡ä»¶ä¸­è¯»å–æ€»èµ„äº§ä¿¡æ¯"""
    try:
        if file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        else:
            df = pd.read_csv(file_path, encoding='utf-8-sig')

        # æŸ¥æ‰¾å¿…è¦çš„åˆ—
        product_col = None
        total_asset_col = None

        for col in df.columns:
            if 'äº§å“åç§°' in col:
                product_col = col
            elif col == 'æ€»èµ„äº§':  # ç²¾ç¡®åŒ¹é…
                total_asset_col = col

        if not product_col or not total_asset_col:
            return None

        # æå–æ•°æ®
        result_df = df[[product_col, total_asset_col]].copy()
        result_df.columns = ['äº§å“åç§°', 'æ€»èµ„äº§']

        # æ•°æ®æ¸…ç†
        result_df['äº§å“åç§°'] = result_df['äº§å“åç§°'].astype(str)
        result_df['æ€»èµ„äº§'] = pd.to_numeric(result_df['æ€»èµ„äº§'], errors='coerce')
        result_df = result_df.dropna(subset=['äº§å“åç§°', 'æ€»èµ„äº§'])
        result_df = result_df[result_df['äº§å“åç§°'] != '']
        result_df = result_df.groupby('äº§å“åç§°').agg({'æ€»èµ„äº§': 'sum'}).reset_index()

        return result_df

    except Exception as e:
        return None

def calculate_simple_returns():
    """ç®€åŒ–çš„æ”¶ç›Šç‡è®¡ç®—"""
    st.subheader("ğŸ“ˆ äº§å“æ”¶ç›Šç‡è®¡ç®—")

    # è·å–æœ€æ–°çš„æŒä»“æ–‡ä»¶
    files = get_latest_holding_files_with_total_assets()

    if len(files) < 2:
        st.error("éœ€è¦è‡³å°‘2ä¸ªä¸åŒæ—¥æœŸçš„æ–‡ä»¶æ¥è®¡ç®—æ”¶ç›Šç‡")
        return

    # å–æœ€æ–°çš„ä¸¤ä¸ªä¸åŒæ—¥æœŸçš„æ–‡ä»¶
    latest_file = files[0]
    previous_file = None

    # æ‰¾åˆ°ä¸åŒæ—¥æœŸçš„æ–‡ä»¶
    for file in files[1:]:
        if file['date'] != latest_file['date']:
            previous_file = file
            break

    if not previous_file:
        st.error("æœªæ‰¾åˆ°ä¸åŒæ—¥æœŸçš„æ–‡ä»¶")
        return

    # è¯»å–æ•°æ®
    latest_data = read_total_assets_from_holding_file(latest_file['file_path'])
    previous_data = read_total_assets_from_holding_file(previous_file['file_path'])

    if latest_data is None or previous_data is None:
        st.error("æ•°æ®è¯»å–å¤±è´¥")
        return

    # è®¡ç®—æ”¶ç›Šç‡
    merged = pd.merge(
        previous_data.rename(columns={'æ€»èµ„äº§': 'å†å²æ€»èµ„äº§'}),
        latest_data.rename(columns={'æ€»èµ„äº§': 'æœ€æ–°æ€»èµ„äº§'}),
        on='äº§å“åç§°',
        how='inner'
    )

    if merged.empty:
        st.error("æ²¡æœ‰åŒ¹é…çš„äº§å“")
        return

    # è®¡ç®—æ”¶ç›Šç‡
    merged['æ”¶ç›Šç‡'] = (merged['æœ€æ–°æ€»èµ„äº§'] / merged['å†å²æ€»èµ„äº§'] - 1) * 100

    st.dataframe(merged)

    # ç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    with col1:
        avg_return = merged['æ”¶ç›Šç‡'].mean()
        st.metric("å¹³å‡æ”¶ç›Šç‡", f"{avg_return:.2f}%")

    with col2:
        max_return = merged['æ”¶ç›Šç‡'].max()
        st.metric("æœ€é«˜æ”¶ç›Šç‡", f"{max_return:.2f}%")

    with col3:
        min_return = merged['æ”¶ç›Šç‡'].min()
        st.metric("æœ€ä½æ”¶ç›Šç‡", f"{min_return:.2f}%")


def read_futures_assets_from_file(file_path):
    """ä»æœŸè´§æ–‡ä»¶ä¸­è¯»å–å¸‚å€¼æƒç›Šä¿¡æ¯"""
    try:
        df = pd.read_excel(file_path)

        # æŸ¥æ‰¾å¿…è¦çš„åˆ—
        product_col = None
        market_value_col = None

        for col in df.columns:
            if 'äº§å“åç§°' in col:
                product_col = col
            elif col == 'å¸‚å€¼æƒç›Š':
                market_value_col = col

        if not product_col or not market_value_col:
            return None

        # æå–æ•°æ®
        result_df = df[[product_col, market_value_col]].copy()
        result_df.columns = ['äº§å“åç§°', 'æœŸè´§èµ„äº§']

        # æ•°æ®æ¸…ç†
        result_df['äº§å“åç§°'] = result_df['äº§å“åç§°'].astype(str)
        result_df['æœŸè´§èµ„äº§'] = pd.to_numeric(result_df['æœŸè´§èµ„äº§'], errors='coerce')
        result_df = result_df.dropna(subset=['äº§å“åç§°', 'æœŸè´§èµ„äº§'])
        result_df = result_df[result_df['äº§å“åç§°'] != '']
        result_df = result_df.groupby('äº§å“åç§°').agg({'æœŸè´§èµ„äº§': 'sum'}).reset_index()

        return result_df

    except Exception as e:
        return None


def get_latest_futures_file_by_date(target_date):
    """è·å–æŒ‡å®šæ—¥æœŸçš„æœ€æ–°æœŸè´§æ–‡ä»¶"""
    futures_dir = r"C:\shared_data\æœŸè´§"

    if not os.path.exists(futures_dir):
        return None

    # æŸ¥æ‰¾æœŸè´§æ–‡ä»¶
    futures_files = []
    for file in os.listdir(futures_dir):
        if file.startswith("æœŸè´§èµ„äº§å¯¼å‡º_") and file.endswith('.xls'):
            try:
                time_part = file.replace('æœŸè´§èµ„äº§å¯¼å‡º_', '').replace('.xls', '')
                timestamp = datetime.strptime(time_part, '%Y%m%d-%H%M%S')
                file_date = timestamp.strftime('%Y%m%d')

                # åŒ¹é…ç›®æ ‡æ—¥æœŸ
                if file_date == target_date:
                    futures_files.append({
                        'file_path': os.path.join(futures_dir, file),
                        'timestamp': timestamp
                    })
            except:
                continue

    # å¦‚æœæ‰¾ä¸åˆ°ç²¾ç¡®åŒ¹é…çš„æ—¥æœŸï¼Œæ‰¾æœ€æ¥è¿‘çš„å†å²æ–‡ä»¶
    if not futures_files:
        all_futures_files = []
        for file in os.listdir(futures_dir):
            if file.startswith("æœŸè´§èµ„äº§å¯¼å‡º_") and file.endswith('.xls'):
                try:
                    time_part = file.replace('æœŸè´§èµ„äº§å¯¼å‡º_', '').replace('.xls', '')
                    timestamp = datetime.strptime(time_part, '%Y%m%d-%H%M%S')
                    file_date = timestamp.strftime('%Y%m%d')

                    # åªè¦æ—¥æœŸå°äºç­‰äºç›®æ ‡æ—¥æœŸå°±å¯ä»¥
                    if file_date <= target_date:
                        all_futures_files.append({
                            'file_path': os.path.join(futures_dir, file),
                            'timestamp': timestamp,
                            'date': file_date
                        })
                except:
                    continue

        if all_futures_files:
            # é€‰æ‹©æœ€æ¥è¿‘ä¸”ä¸è¶…è¿‡ç›®æ ‡æ—¥æœŸçš„æ–‡ä»¶
            latest_futures = max(all_futures_files, key=lambda x: x['timestamp'])
            return latest_futures['file_path']
        else:
            return None
    else:
        # è¿”å›è¯¥æ—¥æœŸæœ€æ–°çš„æœŸè´§æ–‡ä»¶
        latest_futures = max(futures_files, key=lambda x: x['timestamp'])
        return latest_futures['file_path']


def combine_assets_and_futures(assets_data, futures_data, custody_data=None):
    """åˆå¹¶ç°è´§èµ„äº§ã€æœŸè´§èµ„äº§å’Œæ‰˜ç®¡æˆ·èµ„é‡‘"""
    if assets_data is None:
        assets_data = pd.DataFrame(columns=['äº§å“åç§°', 'æ€»èµ„äº§'])
    if futures_data is None:
        futures_data = pd.DataFrame(columns=['äº§å“åç§°', 'æœŸè´§èµ„äº§'])
    if custody_data is None:
        custody_data = pd.DataFrame(columns=['äº§å“åç§°', 'æ‰˜ç®¡èµ„é‡‘'])

    # å¤–è¿æ¥åˆå¹¶
    combined = pd.merge(assets_data, futures_data, on='äº§å“åç§°', how='outer')
    combined = pd.merge(combined, custody_data, on='äº§å“åç§°', how='outer')
    combined = combined.fillna(0)

    # è®¡ç®—çœŸå®æ€»èµ„äº§ = ç°è´§ + æœŸè´§ + æ‰˜ç®¡
    combined['çœŸå®æ€»èµ„äº§'] = combined['æ€»èµ„äº§'] + combined['æœŸè´§èµ„äº§'] + combined['æ‰˜ç®¡èµ„é‡‘']

    return combined[['äº§å“åç§°', 'çœŸå®æ€»èµ„äº§']]

def combine_assets_and_futures_without_custody(assets_data, futures_data):
    """åˆå¹¶ç°è´§èµ„äº§ã€æœŸè´§èµ„äº§å’Œæ‰˜ç®¡æˆ·èµ„é‡‘"""
    if assets_data is None:
        assets_data = pd.DataFrame(columns=['äº§å“åç§°', 'æ€»èµ„äº§'])
    if futures_data is None:
        futures_data = pd.DataFrame(columns=['äº§å“åç§°', 'æœŸè´§èµ„äº§'])

    # å¤–è¿æ¥åˆå¹¶
    combined = pd.merge(assets_data, futures_data, on='äº§å“åç§°', how='outer')
    combined = combined.fillna(0)

    # è®¡ç®—çœŸå®æ€»èµ„äº§ = ç°è´§ + æœŸè´§ + æ‰˜ç®¡
    combined['çœŸå®æ€»èµ„äº§'] = combined['æ€»èµ„äº§'] + combined['æœŸè´§èµ„äº§']

    return combined[['äº§å“åç§°', 'çœŸå®æ€»èµ„äº§']]

