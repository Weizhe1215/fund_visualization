"""
æŒä»“æ•°æ®è‡ªåŠ¨æ›´æ–°ç»„ä»¶
"""
import streamlit as st
import pandas as pd
import os
import glob
from datetime import datetime, timedelta
import time

# æ•°æ®è·¯å¾„é…ç½®
DATA_PATHS = {
    "å®ç›˜": r"C:\shared_data\å®ç›˜\äº¤æ˜“æ•°æ®å®šé¢‘å¯¼å‡º",
    "ä»¿çœŸ": r"C:\shared_data\ä»¿çœŸ\äº¤æ˜“æ•°æ®å®šé¢‘å¯¼å‡º"
}

def add_exchange_suffix(stock_code):
    """ä¸ºè‚¡ç¥¨ä»£ç æ·»åŠ äº¤æ˜“æ‰€åç¼€"""
    code = str(stock_code).zfill(6)  # ç¡®ä¿æ˜¯6ä½æ•°å­—

    # æ²ªå¸‚ï¼š6å¼€å¤´çš„è‚¡ç¥¨ï¼Œ688/689å¼€å¤´çš„ç§‘åˆ›æ¿ï¼Œ1å¼€å¤´çš„è½¬å€º
    if code.startswith('6') or code.startswith('688') or code.startswith('689') or code.startswith('1'):
        return f"{code}.SH"
    # æ·±å¸‚ï¼š0/3å¼€å¤´çš„è‚¡ç¥¨ï¼Œå…¶ä»–è½¬å€º
    else:
        return f"{code}.SZ"


def get_all_holdings_files(data_source="å®ç›˜", target_time="150000"):
    """è·å–æŒ‡å®šæ•°æ®æºæ‰€æœ‰æ—¥æœŸçš„æŒä»“æ–‡ä»¶"""
    try:
        base_path = DATA_PATHS[data_source]
        if not os.path.exists(base_path):
            return {"error": f"è·¯å¾„ä¸å­˜åœ¨: {base_path}"}

        # è·å–æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹å¹¶æ’åº
        date_folders = [f for f in os.listdir(base_path)
                        if f.isdigit() and len(f) == 8 and os.path.isdir(os.path.join(base_path, f))]

        if not date_folders:
            return {"error": "æœªæ‰¾åˆ°æ—¥æœŸæ–‡ä»¶å¤¹"}

        date_folders.sort()  # æŒ‰æ—¥æœŸæ’åº

        # æŒ‰æ—¥æœŸæ”¶é›†æ–‡ä»¶
        date_files = {}
        total_files = 0

        for date_folder in date_folders:
            date_folder_path = os.path.join(base_path, date_folder)

            # æŸ¥æ‰¾è¯¥æ—¥æœŸçš„150000æ—¶é—´æ–‡ä»¶
            target_files = []
            for root, dirs, files in os.walk(date_folder_path):
                for file in files:
                    if (file.startswith("å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º") and
                            file.endswith('.xlsx') and
                            target_time in file):
                        target_files.append(os.path.join(root, file))

            if target_files:
                date_files[date_folder] = target_files
                total_files += len(target_files)

        return {
            "success": True,
            "date_files": date_files,  # æŒ‰æ—¥æœŸåˆ†ç»„çš„æ–‡ä»¶
            "data_source": data_source,
            "debug_info": {
                "total_dates": len(date_files),
                "total_files": total_files,
                "date_list": list(date_files.keys()),
                "search_path": base_path
            }
        }

    except Exception as e:
        return {"error": f"è¯»å–{data_source}æ–‡ä»¶å¤±è´¥: {str(e)}"}


def read_holdings_file(file_path):
    """è¯»å–å•ä¸ªæŒä»“æ–‡ä»¶"""
    try:
        df = pd.read_excel(file_path)

        # æŸ¥æ‰¾éœ€è¦çš„åˆ—
        product_col = None
        stock_code_col = None
        market_value_col = None

        for col in df.columns:
            if 'äº§å“åç§°' in col:
                product_col = col
            elif 'è¯åˆ¸ä»£ç ' in col:
                stock_code_col = col
            elif 'æŒä»“å¸‚å€¼' in col:
                market_value_col = col

        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
        if not all([product_col, stock_code_col, market_value_col]):
            return {"error": f"ç¼ºå°‘å¿…éœ€åˆ—ï¼Œæ–‡ä»¶: {os.path.basename(file_path)}"}

        # æå–éœ€è¦çš„æ•°æ®
        result_df = df[[product_col, stock_code_col, market_value_col]].copy()
        result_df.columns = ['product_name', 'stock_code', 'market_value']

        # æ•°æ®æ¸…ç†
        result_df['product_name'] = result_df['product_name'].astype(str)
        result_df['stock_code'] = result_df['stock_code'].astype(str).str.zfill(6)
        result_df['market_value'] = pd.to_numeric(result_df['market_value'], errors='coerce')

        # åˆ é™¤æ— æ•ˆæ•°æ®
        result_df = result_df.dropna(subset=['product_name', 'stock_code', 'market_value'])
        result_df = result_df[result_df['market_value'] > 0]

        # æ·»åŠ äº¤æ˜“æ‰€åç¼€
        result_df['stock_code'] = result_df['stock_code'].apply(add_exchange_suffix)

        return {"success": True, "data": result_df}

    except Exception as e:
        return {"error": f"è¯»å–æ–‡ä»¶å¤±è´¥ {os.path.basename(file_path)}: {str(e)}"}


def update_holdings_to_database(db, holdings_data, date_str):
    """å°†æŒä»“æ•°æ®æ›´æ–°åˆ°æ•°æ®åº“"""
    try:

        # æŒ‰äº§å“åˆ†ç»„å¤„ç†
        updated_products = []

        for product_name in holdings_data['product_name'].unique():


            # è·å–è¯¥äº§å“çš„æŒä»“æ•°æ®
            product_data = holdings_data[holdings_data['product_name'] == product_name].copy()


            # æŒ‰è‚¡ç¥¨ä»£ç åˆå¹¶ï¼ˆåŒä¸€äº§å“å¯èƒ½æœ‰å¤šæ¡è®°å½•ï¼‰
            merged_data = product_data.groupby('stock_code').agg({
                'market_value': 'sum',
                'product_name': 'first'
            }).reset_index()


            # è®¡ç®—æŒä»“æ¯”ä¾‹
            total_value = merged_data['market_value'].sum()
            if total_value > 0:
                merged_data['position_ratio'] = (merged_data['market_value'] / total_value) * 100
            else:
                merged_data['position_ratio'] = 0

            # æ·»åŠ å…¶ä»–å¿…éœ€åˆ—
            # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡® (YYYYMMDD -> YYYY-MM-DD)
            if len(date_str) == 8:  # å¦‚æœæ˜¯YYYYMMDDæ ¼å¼
                formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
            else:
                formatted_date = date_str
            merged_data['date'] = formatted_date
            merged_data['stock_name'] = ''  # æš‚æ—¶ç•™ç©º
            merged_data['shares'] = None

            # æ£€æŸ¥äº§å“æ˜¯å¦åœ¨æ•°æ®åº“ä¸­å­˜åœ¨
            db_products = db.get_products()
            product_code = None
            for p in db_products:
                if p['product_name'] == product_name:
                    product_code = p['product_code']
                    break

            if product_code:
                # å‡†å¤‡æ•°æ®æ ¼å¼
                final_data = merged_data[
                    ['date', 'stock_code', 'stock_name', 'position_ratio', 'market_value', 'shares']]

                # æ›´æ–°åˆ°æ•°æ®åº“
                success = db.add_holdings_data(product_code, final_data)
                if success:
                    updated_products.append(product_name)
            else:
                print(f"  æœªæ‰¾åˆ°åŒ¹é…çš„äº§å“ä»£ç ï¼Œè·³è¿‡")

        return {
            "success": True,
            "updated_products": updated_products,
            "total_records": len(holdings_data)
        }

    except Exception as e:
        pass
        return {"error": f"æ•°æ®åº“æ›´æ–°å¤±è´¥: {str(e)}"}


def update_holdings_from_source(db, data_source="å®ç›˜", target_time="150000"):
    """ä»æŒ‡å®šæ•°æ®æºæ›´æ–°æ‰€æœ‰æ—¥æœŸçš„æŒä»“æ•°æ®"""
    try:
        # è·å–æ‰€æœ‰æ—¥æœŸçš„æ–‡ä»¶åˆ—è¡¨
        file_result = get_all_holdings_files(data_source, target_time)

        if "error" in file_result:
            return file_result

        date_files = file_result.get("date_files", {})
        if not date_files:
            return {
                "error": f"æœªæ‰¾åˆ°{data_source}çš„{target_time}æ—¶é—´æŒä»“æ–‡ä»¶",
                "debug_info": file_result.get("debug_info", {})
            }

        # æŒ‰æ—¥æœŸå¤„ç†
        updated_dates = []
        failed_dates = []
        total_updated_products = set()

        for date_str, files in date_files.items():
            try:
                # è¯»å–è¯¥æ—¥æœŸçš„æ‰€æœ‰æ–‡ä»¶
                date_holdings = []

                for file_path in files:
                    read_result = read_holdings_file(file_path)
                    if "error" not in read_result:
                        date_holdings.append(read_result["data"])

                if date_holdings:
                    # åˆå¹¶è¯¥æ—¥æœŸçš„æ‰€æœ‰æŒä»“æ•°æ®
                    combined_holdings = pd.concat(date_holdings, ignore_index=True)

                    # æ›´æ–°åˆ°æ•°æ®åº“
                    update_result = update_holdings_to_database(db, combined_holdings, date_str)

                    if update_result.get("success"):
                        updated_dates.append(date_str)
                        total_updated_products.update(update_result.get("updated_products", []))
                    else:
                        failed_dates.append({"date": date_str, "error": update_result.get("error")})
                else:
                    failed_dates.append({"date": date_str, "error": "æ‰€æœ‰æ–‡ä»¶è¯»å–å¤±è´¥"})

            except Exception as e:
                failed_dates.append({"date": date_str, "error": str(e)})

        return {
            "success": True,
            "updated_dates": updated_dates,
            "failed_dates": failed_dates,
            "data_source": data_source,
            "total_updated_products": list(total_updated_products),
            "debug_info": file_result.get("debug_info", {})
        }

    except Exception as e:
        return {"error": f"æ‰¹é‡æ›´æ–°æŒä»“æ•°æ®å¤±è´¥: {str(e)}"}


def render_holdings_update_section(db):
    """æ¸²æŸ“æ•°æ®æ›´æ–°UIç»„ä»¶"""
    st.subheader("ğŸ“Š æ•°æ®æ›´æ–°")

    # åˆ›å»ºä¸¤åˆ—ï¼šæŒä»“æ›´æ–° | å‡€å€¼æ›´æ–°
    col_holdings, col_nav = st.columns(2)

    # æŒä»“æ›´æ–°åˆ—
    with col_holdings:
        st.write("**ğŸ“‹ æŒä»“æ•°æ®æ›´æ–°**")

        data_source = st.selectbox(
            "æ•°æ®æº",
            options=["å®ç›˜", "ä»¿çœŸ"],
            key="holdings_update_source"
        )

        if st.button("ğŸ”„ æ›´æ–°æŒä»“", type="primary", use_container_width=True):
            with st.spinner(f"æ­£åœ¨ä»{data_source}æ›´æ–°æŒä»“æ•°æ®..."):
                result = update_holdings_from_source(db, data_source)

                if result.get("success"):
                    st.success(f"âœ… æ›´æ–°æˆåŠŸï¼")
                    if result.get("updated_dates"):
                        st.info(f"ğŸ“… æ›´æ–°æ—¥æœŸ: {len(result['updated_dates'])}å¤©")
                    if result.get("total_updated_products"):
                        st.info(f"ğŸ“Š æ›´æ–°äº§å“: {', '.join(result['total_updated_products'])}")
                else:
                    st.error(f"âŒ æ›´æ–°å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        # æŒä»“æ›´æ–°è¯´æ˜
        st.caption("ğŸ“‚ ä»äº¤æ˜“æ•°æ®å®šé¢‘å¯¼å‡ºè¯»å–15:00æŒä»“")

        # è‡ªåŠ¨æ›´æ–°çŠ¶æ€
        current_time = datetime.now()
        if current_time.hour == 15 and current_time.minute >= 5:
            st.info("ğŸ“… ä»Šæ—¥å·²è¿‡è‡ªåŠ¨æ›´æ–°æ—¶é—´(15:05)")
        else:
            st.info("ğŸ“… æ¯æ—¥15:05è‡ªåŠ¨æ›´æ–°")

    # å‡€å€¼æ›´æ–°åˆ—
    with col_nav:
        st.write("**ğŸ“ˆ å‡€å€¼æ•°æ®æ›´æ–°**")

        # å ä½ï¼Œä¿æŒä¸æŒä»“åˆ—å¯¹é½
        st.write("")  # å ä½æ›¿ä»£selectboxçš„ç©ºé—´

        if st.button("ğŸ“ˆ æ›´æ–°å‡€å€¼", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨ä»è´¦æˆ·èµ„äº§æ–‡ä»¶æ›´æ–°å‡€å€¼æ•°æ®..."):
                # è¯»å–å‡€å€¼æ•°æ®
                nav_result = update_nav_from_excel()

                if nav_result.get("success"):
                    # æ›´æ–°åˆ°æ•°æ®åº“
                    update_result = update_nav_to_database(db, nav_result["nav_data"])

                    if update_result.get("success"):
                        st.success(f"âœ… å‡€å€¼æ›´æ–°æˆåŠŸï¼")
                        st.info(f"ğŸ“Š æ›´æ–°äº§å“: {', '.join(update_result['updated_products'])}")
                        st.info(f"ğŸ“„ å¤„ç†Sheet: {update_result['total_sheets']}ä¸ª")
                    else:
                        st.error(f"âŒ å‡€å€¼æ›´æ–°å¤±è´¥: {update_result.get('error')}")
                else:
                    st.error(f"âŒ è¯»å–å‡€å€¼æ–‡ä»¶å¤±è´¥: {nav_result.get('error')}")

        # å‡€å€¼æ›´æ–°è¯´æ˜
        st.caption("ğŸ“„ ä»è´¦æˆ·èµ„äº§.xlsxè¯»å–å‡€å€¼æ•°æ®")
        st.caption("ğŸ” è‡ªåŠ¨åŒ¹é…äº§å“åç§°å’Œk-å‰ç¼€")


def read_nav_excel_file(file_path):
    """è¯»å–è´¦æˆ·èµ„äº§Excelæ–‡ä»¶ï¼Œè¿”å›æ‰€æœ‰sheetçš„å‡€å€¼æ•°æ®"""
    try:
        import pandas as pd

        # è¯»å–æ‰€æœ‰sheet
        all_sheets = pd.read_excel(file_path, sheet_name=None)

        nav_data_by_product = {}

        for sheet_name, df in all_sheets.items():
            if df.empty:
                continue

            # æŸ¥æ‰¾å‡€å€¼åˆ—
            nav_col = None
            for col in df.columns:
                if 'å‡€å€¼' in str(col) or 'NAV' in str(col).upper() or 'å•ä½å‡€å€¼' in str(col):
                    nav_col = col
                    break

            if nav_col is None:
                continue

            # ç¬¬ä¸€åˆ—ä½œä¸ºæ—¥æœŸåˆ—
            date_col = df.columns[0]

            # æå–æ•°æ®
            result_df = df[[date_col, nav_col]].copy()
            result_df.columns = ['date', 'nav_value']

            # æ•°æ®æ¸…ç†
            result_df = result_df.dropna(subset=['date', 'nav_value'])
            result_df['nav_value'] = pd.to_numeric(result_df['nav_value'], errors='coerce')
            result_df = result_df.dropna(subset=['nav_value'])

            # âœ… æ–°å¢ï¼šåªä¿ç•™å‡€å€¼å¤§äº0çš„æ•°æ®
            result_df = result_df[result_df['nav_value'] > 0]

            # æ—¥æœŸæ ¼å¼å¤„ç†
            try:
                result_df['date'] = pd.to_datetime(result_df['date']).dt.strftime('%Y-%m-%d')
            except:
                continue

            # âœ… æ–°å¢ï¼šæŒ‰æ—¥æœŸæ’åºï¼Œç¡®ä¿æ•°æ®çš„è¿ç»­æ€§
            result_df = result_df.sort_values('date')

            # âœ… æ–°å¢ï¼šåªä¿ç•™åˆ°æ˜¨å¤©ä¸ºæ­¢çš„æ•°æ®
            from datetime import datetime, timedelta
            yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
            result_df = result_df[result_df['date'] <= yesterday]

            if not result_df.empty:
                nav_data_by_product[sheet_name] = result_df

        return {"success": True, "data": nav_data_by_product}

    except Exception as e:
        return {"error": f"è¯»å–å‡€å€¼æ–‡ä»¶å¤±è´¥: {str(e)}"}


def update_nav_to_database(db, nav_data_dict):
    """å°†å‡€å€¼æ•°æ®æ›´æ–°åˆ°æ•°æ®åº“"""
    try:
        updated_products = []

        # è·å–æ•°æ®åº“ä¸­çš„äº§å“åˆ—è¡¨
        db_products = db.get_products()
        db_product_names = {p['product_name']: p['product_code'] for p in db_products}

        for sheet_name, nav_df in nav_data_dict.items():
            # å°è¯•åŒ¹é…äº§å“åç§°
            product_code = None

            # 1. ç²¾ç¡®åŒ¹é…
            if sheet_name in db_product_names:
                product_code = db_product_names[sheet_name]
            else:
                # 2. å»é™¤ç©ºæ ¼çš„åŒ¹é…
                for db_name, db_code in db_product_names.items():
                    if sheet_name.strip() == db_name.strip():
                        product_code = db_code
                        break

                # 3. å¤„ç† "k-XXXX" æ ¼å¼çš„åŒ¹é…
                if product_code is None and sheet_name.startswith('k-'):
                    # æå–k-åé¢çš„éƒ¨åˆ†
                    name_part = sheet_name[2:].strip()  # å»æ‰"k-"å‰ç¼€

                    for db_name, db_code in db_product_names.items():
                        # æ£€æŸ¥æ•°æ®åº“ä¸­çš„äº§å“åæ˜¯å¦åŒ…å«è¿™ä¸ªåç§°éƒ¨åˆ†
                        if name_part in db_name or db_name in name_part:
                            product_code = db_code
                            break

                # 4. æ›´å®½æ¾çš„åŒ…å«åŒ¹é…
                if product_code is None:
                    for db_name, db_code in db_product_names.items():
                        # äº’ç›¸åŒ…å«çš„åŒ¹é…
                        if (sheet_name.lower().strip() in db_name.lower().strip() or
                                db_name.lower().strip() in sheet_name.lower().strip()):
                            product_code = db_code
                            break

            if product_code:
                # æ·»åŠ ç´¯è®¡å‡€å€¼åˆ—ï¼ˆè®¾ä¸ºä¸å•ä½å‡€å€¼ç›¸åŒï¼‰
                nav_df['cumulative_nav'] = nav_df['nav_value']

                # æ›´æ–°åˆ°æ•°æ®åº“
                success = db.add_nav_data(product_code, nav_df)
                if success:
                    updated_products.append(f"{sheet_name} â†’ {product_code}")
            else:
                # è®°å½•æœªåŒ¹é…çš„sheet
                print(f"æœªåŒ¹é…çš„Sheet: {sheet_name}")

        return {
            "success": True,
            "updated_products": updated_products,
            "total_sheets": len(nav_data_dict)
        }

    except Exception as e:
        return {"error": f"å‡€å€¼æ•°æ®åº“æ›´æ–°å¤±è´¥: {str(e)}"}


def update_nav_from_excel():
    """ä»è´¦æˆ·èµ„äº§Excelæ–‡ä»¶æ›´æ–°å‡€å€¼æ•°æ®"""
    file_path = r"C:\shared_data\è´¦æˆ·èµ„äº§.xlsx"

    if not os.path.exists(file_path):
        return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}

    # è¯»å–Excelæ–‡ä»¶
    read_result = read_nav_excel_file(file_path)

    if "error" in read_result:
        return read_result

    nav_data = read_result["data"]
    if not nav_data:
        return {"error": "æœªæ‰¾åˆ°æœ‰æ•ˆçš„å‡€å€¼æ•°æ®"}

    return {
        "success": True,
        "nav_data": nav_data,
        "total_sheets": len(nav_data)
    }


