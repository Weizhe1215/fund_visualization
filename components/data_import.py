"""
æ•°æ®å¯¼å…¥ç»„ä»¶
"""
import streamlit as st
import pandas as pd
import io
from config import COLUMN_MAPPING, SUPPORTED_FILE_FORMATS

def detect_and_map_columns(df, data_type='nav'):
    """è‡ªåŠ¨æ£€æµ‹å’Œæ˜ å°„åˆ—å"""
    if data_type == 'nav':
        column_mapping = COLUMN_MAPPING['nav_columns']
    else:  # holdings
        column_mapping = COLUMN_MAPPING['holdings_columns']

    mapped_columns = {}
    df_columns = df.columns.tolist()

    for standard_col, possible_names in column_mapping.items():
        for col in df_columns:
            if col in possible_names:
                mapped_columns[col] = standard_col
                break

    return mapped_columns

def process_nav_data(df, column_mapping):
    """å¤„ç†å‡€å€¼æ•°æ®"""
    # é‡å‘½ååˆ—
    df_processed = df.rename(columns=column_mapping)

    # æ£€æŸ¥å¿…éœ€åˆ—
    required_cols = ['date', 'nav_value']
    missing_cols = [col for col in required_cols if col not in df_processed.columns]

    if missing_cols:
        raise ValueError(f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")

    # æ•°æ®ç±»å‹è½¬æ¢å’Œæ¸…ç†
    df_processed['date'] = pd.to_datetime(df_processed['date']).dt.strftime('%Y-%m-%d')
    df_processed['nav_value'] = pd.to_numeric(df_processed['nav_value'], errors='coerce')

    if 'cumulative_nav' in df_processed.columns:
        df_processed['cumulative_nav'] = pd.to_numeric(df_processed['cumulative_nav'], errors='coerce')
    else:
        df_processed['cumulative_nav'] = None

    # åˆ é™¤æ— æ•ˆè¡Œ
    df_processed = df_processed.dropna(subset=['nav_value'])

    return df_processed[['date', 'nav_value', 'cumulative_nav']]

def process_holdings_data(df, column_mapping, data_format='matrix'):
    """å¤„ç†æŒä»“æ•°æ®"""

    if data_format == 'matrix':
        # çŸ©é˜µæ ¼å¼ï¼šè¡Œæ˜¯æ—¥æœŸï¼Œåˆ—æ˜¯è‚¡ç¥¨tickerï¼Œå€¼æ˜¯è£¸æƒé‡
        date_col = df.columns[0]

        # å°†çŸ©é˜µè½¬æ¢ä¸ºé•¿æ ¼å¼
        df_long = df.melt(
            id_vars=[date_col],
            var_name='stock_code',
            value_name='raw_weight'
        )

        # é‡å‘½åæ—¥æœŸåˆ—
        df_long = df_long.rename(columns={date_col: 'date'})

        # å¤„ç†æ—¥æœŸ - æ”¯æŒYYYYMMDDæ ¼å¼
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºYYYYMMDDæ ¼å¼
            sample_date = str(df_long['date'].iloc[0])
            if len(sample_date) == 8 and sample_date.isdigit():
                df_long['date'] = pd.to_datetime(df_long['date'].astype(str), format='%Y%m%d').dt.strftime('%Y-%m-%d')
            else:
                df_long['date'] = pd.to_datetime(df_long['date']).dt.strftime('%Y-%m-%d')
        except:
            raise ValueError("æ—¥æœŸæ ¼å¼æ— æ³•è§£æï¼Œè¯·ç¡®ä¿æ—¥æœŸæ ¼å¼ä¸º YYYYMMDD")

        # å¤„ç†æƒé‡æ•°æ®
        df_long['stock_code'] = df_long['stock_code'].astype(str)
        df_long['raw_weight'] = pd.to_numeric(df_long['raw_weight'], errors='coerce')

        # åˆ é™¤æ— æ•ˆæ•°æ®
        df_long = df_long.dropna(subset=['date', 'raw_weight'])
        df_long = df_long[df_long['raw_weight'] > 0]

        if df_long.empty:
            raise ValueError("å¤„ç†åæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")

        # è®¡ç®—ç›¸å¯¹æƒé‡
        daily_totals = df_long.groupby('date')['raw_weight'].sum()
        df_long = df_long.merge(daily_totals.rename('daily_total'), left_on='date', right_index=True)
        df_long['position_ratio'] = (df_long['raw_weight'] / df_long['daily_total']) * 100

        # æ·»åŠ å…¶ä»–åˆ—
        df_long['stock_name'] = df_long['stock_code']
        df_long['market_value'] = None
        df_long['shares'] = None

        return df_long[['date', 'stock_code', 'stock_name', 'position_ratio', 'market_value', 'shares']]

    else:
        # é•¿æ ¼å¼å¤„ç†
        df_processed = df.rename(columns=column_mapping)

        required_cols = ['date', 'stock_code']
        missing_cols = [col for col in required_cols if col not in df_processed.columns]

        if missing_cols:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")

        df_processed['date'] = pd.to_datetime(df_processed['date']).dt.strftime('%Y-%m-%d')
        df_processed['stock_code'] = df_processed['stock_code'].astype(str)

        for col in ['position_ratio', 'market_value', 'shares']:
            if col in df_processed.columns:
                df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')
            else:
                df_processed[col] = None

        if 'stock_name' not in df_processed.columns:
            df_processed['stock_name'] = df_processed['stock_code']

        df_processed = df_processed.dropna(subset=['stock_code'])
        df_processed = df_processed[df_processed['stock_code'] != '']

        return df_processed[['date', 'stock_code', 'stock_name', 'position_ratio', 'market_value', 'shares']]

def render_data_import(db):
    """æ¸²æŸ“æ•°æ®å¯¼å…¥é¡µé¢"""
    st.header("ğŸ“¤ æ•°æ®å¯¼å…¥")

    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ äº§å“ç®¡ç†", "ğŸ“ˆ å‡€å€¼æ•°æ®", "ğŸ“Š æŒä»“æ•°æ®"])

    with tab1:
        render_product_management(db)

    with tab2:
        render_nav_import(db)

    with tab3:
        render_holdings_import(db)

def render_product_management(db):
    """æ¸²æŸ“äº§å“ç®¡ç†é¡µé¢"""
    st.subheader("äº§å“ç®¡ç†")

    products = db.get_products()
    if products:
        st.write("**ç°æœ‰äº§å“ï¼š**")

        for product in products:
            with st.container():
                col1, col2, col3, col4 = st.columns([2, 3, 2, 1])

                with col1:
                    st.text(product['product_code'])
                with col2:
                    st.text(product['product_name'])
                with col3:
                    summary = db.get_product_data_summary(product['product_code'])
                    st.caption(f"å‡€å€¼: {summary['nav_records']}æ¡ | æŒä»“: {summary['holdings_dates']}æ—¥")
                with col4:
                    if st.button("ğŸ—‘ï¸", key=f"del_{product['product_code']}",
                               help="åˆ é™¤äº§å“", type="secondary"):
                        st.session_state[f"confirm_delete_{product['product_code']}"] = True

                # ç¡®è®¤åˆ é™¤å¯¹è¯æ¡†
                if st.session_state.get(f"confirm_delete_{product['product_code']}", False):
                    st.warning(f"âš ï¸ ç¡®è®¤åˆ é™¤äº§å“ **{product['product_name']} ({product['product_code']})**ï¼Ÿ")
                    st.caption("è¿™å°†åˆ é™¤è¯¥äº§å“çš„æ‰€æœ‰å‡€å€¼å’ŒæŒä»“æ•°æ®ï¼Œä¸”ä¸å¯æ¢å¤ï¼")

                    col_yes, col_no, col_space = st.columns([1, 1, 3])
                    with col_yes:
                        if st.button("ç¡®è®¤åˆ é™¤", key=f"confirm_yes_{product['product_code']}",
                                   type="primary"):
                            success = db.delete_product(product['product_code'])
                            if success:
                                st.success("äº§å“åˆ é™¤æˆåŠŸï¼")
                                if f"confirm_delete_{product['product_code']}" in st.session_state:
                                    del st.session_state[f"confirm_delete_{product['product_code']}"]
                                st.rerun()
                            else:
                                st.error("åˆ é™¤å¤±è´¥")

                    with col_no:
                        if st.button("å–æ¶ˆ", key=f"confirm_no_{product['product_code']}"):
                            if f"confirm_delete_{product['product_code']}" in st.session_state:
                                del st.session_state[f"confirm_delete_{product['product_code']}"]
                            st.rerun()

                st.divider()

        st.write("**æ•°æ®ç®¡ç†ï¼š**")
        if products:
            selected_product_for_data = st.selectbox(
                "é€‰æ‹©äº§å“è¿›è¡Œæ•°æ®ç®¡ç†",
                options=[f"{p['product_name']} ({p['product_code']})" for p in products],
                key="data_management_product"
            )

            if selected_product_for_data:
                product_code = selected_product_for_data.split('(')[1].split(')')[0]
                summary = db.get_product_data_summary(product_code)

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("å‡€å€¼è®°å½•", summary['nav_records'])
                    if summary['nav_records'] > 0:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤å‡€å€¼æ•°æ®", key=f"del_nav_{product_code}"):
                            success = db.delete_product_nav_data(product_code)
                            if success:
                                st.success("å‡€å€¼æ•°æ®åˆ é™¤æˆåŠŸï¼")
                                st.rerun()

                with col2:
                    st.metric("æŒä»“è®°å½•", f"{summary['holdings_records']} ({summary['holdings_dates']}æ—¥)")
                    if summary['holdings_records'] > 0:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤æŒä»“æ•°æ®", key=f"del_holdings_{product_code}"):
                            success = db.delete_product_holdings_data(product_code)
                            if success:
                                st.success("æŒä»“æ•°æ®åˆ é™¤æˆåŠŸï¼")
                                st.rerun()

    else:
        st.info("æš‚æ— äº§å“")

    st.divider()

    st.write("**æ·»åŠ æ–°äº§å“ï¼š**")
    with st.form("add_product_form"):
        col1, col2 = st.columns(2)
        with col1:
            product_code = st.text_input("äº§å“ä»£ç *", placeholder="ä¾‹å¦‚: FUND001")
        with col2:
            product_name = st.text_input("äº§å“åç§°*", placeholder="ä¾‹å¦‚: ä»·å€¼æˆé•¿åŸºé‡‘")

        description = st.text_area("äº§å“æè¿°", placeholder="å¯é€‰ï¼Œäº§å“çš„è¯¦ç»†æè¿°")

        submitted = st.form_submit_button("â• æ·»åŠ äº§å“", type="primary")

        if submitted:
            if product_code and product_name:
                success = db.add_product(product_code, product_name, description)
                if success:
                    st.success("äº§å“æ·»åŠ æˆåŠŸï¼")
                    st.rerun()
                else:
                    st.error("äº§å“æ·»åŠ å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç æ˜¯å¦é‡å¤")
            else:
                st.error("è¯·å¡«å†™äº§å“ä»£ç å’Œåç§°")


def render_nav_import(db):
    """æ¸²æŸ“å‡€å€¼æ•°æ®å¯¼å…¥"""
    st.subheader("å¯¼å…¥å‡€å€¼æ•°æ®")

    # äº§å“é€‰æ‹©
    products = db.get_products()
    if not products:
        st.warning("è¯·å…ˆæ·»åŠ äº§å“")
        return

    product_options = {f"{p['product_name']} ({p['product_code']})": p['product_code'] for p in products}
    selected_product = st.selectbox("é€‰æ‹©äº§å“", options=list(product_options.keys()))
    product_code = product_options[selected_product]

    # å¤åˆ¶ç²˜è´´å¯¼å…¥
    st.write("**æ–¹å¼1ï¼šå¤åˆ¶ç²˜è´´å¯¼å…¥**")

    with st.expander("ğŸ“‹ å¤åˆ¶ç²˜è´´å‡€å€¼æ•°æ®"):
        st.info("ä»Excelå¤åˆ¶æ—¥æœŸå’Œå‡€å€¼æ•°æ®ï¼Œç²˜è´´åˆ°ä¸‹æ–¹æ–‡æœ¬æ¡†ä¸­")

        # æ˜¾ç¤ºæ ¼å¼è¯´æ˜
        st.markdown("""
        **æ”¯æŒæ ¼å¼ï¼š**
        ```
        2024/12/31  1.0
        2025/01/02  1.1
        2025/01/03  1.05
        ```
        """)

        # æ–‡æœ¬è¾“å…¥æ¡†
        pasted_data = st.text_area(
            "ç²˜è´´æ•°æ®",
            height=200,
            placeholder="è¯·å°†Excelä¸­çš„æ—¥æœŸå’Œå‡€å€¼æ•°æ®ç²˜è´´åˆ°è¿™é‡Œ...",
            key="nav_paste_input"
        )

        if pasted_data.strip():
            try:
                # è§£æç²˜è´´çš„æ•°æ®
                lines = [line.strip() for line in pasted_data.strip().split('\n') if line.strip()]

                parsed_data = []
                for line in lines:
                    # åˆ†å‰²æ—¥æœŸå’Œå‡€å€¼ï¼ˆæ”¯æŒç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ç­‰åˆ†éš”ç¬¦ï¼‰
                    parts = line.split()
                    if len(parts) >= 2:
                        date_str = parts[0]
                        nav_value = float(parts[1])

                        # è§£ææ—¥æœŸ
                        try:
                            if '/' in date_str:
                                date_obj = pd.to_datetime(date_str, format='%Y/%m/%d')
                            elif '-' in date_str:
                                date_obj = pd.to_datetime(date_str, format='%Y-%m-%d')
                            else:
                                date_obj = pd.to_datetime(date_str)

                            parsed_data.append({
                                'date': date_obj.strftime('%Y-%m-%d'),
                                'nav_value': nav_value,
                                'cumulative_nav': nav_value  # æš‚æ—¶è®¾ä¸ºç›¸åŒå€¼
                            })
                        except:
                            st.warning(f"æ— æ³•è§£ææ—¥æœŸï¼š{date_str}")

                if parsed_data:
                    paste_df = pd.DataFrame(parsed_data)
                    st.write("**è§£æç»“æœé¢„è§ˆï¼š**")
                    st.dataframe(paste_df, use_container_width=True)

                    if st.button("ğŸš€ å¯¼å…¥ç²˜è´´çš„å‡€å€¼æ•°æ®", type="primary", key="import_pasted_nav"):
                        try:
                            # è·å–ç°æœ‰å‡€å€¼æ•°æ®
                            existing_nav = db.get_nav_data(product_code)

                            if not existing_nav.empty:
                                # åˆå¹¶æ–°æ—§æ•°æ®ï¼Œå»é‡ï¼ˆä»¥æ–°æ•°æ®ä¸ºå‡†ï¼‰
                                combined_df = pd.concat([existing_nav, paste_df], ignore_index=True)
                                # æŒ‰æ—¥æœŸå»é‡ï¼Œä¿ç•™æœ€åä¸€ä¸ªï¼ˆæ–°æ•°æ®ï¼‰
                                combined_df = combined_df.drop_duplicates(subset=['date'], keep='last')
                                success = db.add_nav_data(product_code, combined_df, merge_mode=True)
                            else:
                                success = db.add_nav_data(product_code, paste_df, merge_mode=True)

                            if success:
                                st.success(f"æˆåŠŸå¯¼å…¥ {len(paste_df)} æ¡å‡€å€¼è®°å½•ï¼")
                                st.balloons()
                            else:
                                st.error("å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
                        except Exception as e:
                            st.error(f"æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")
                else:
                    st.warning("æœªèƒ½è§£æå‡ºæœ‰æ•ˆæ•°æ®")

            except Exception as e:
                st.error(f"æ•°æ®è§£æå¤±è´¥ï¼š{str(e)}")

    st.divider()
    st.write("**æ–¹å¼2ï¼šæ–‡ä»¶ä¸Šä¼ **")

    with st.expander("ğŸ“‹ æŸ¥çœ‹æ•°æ®æ ¼å¼è¦æ±‚"):
        st.markdown("""
        **å¿…éœ€åˆ—ï¼š**
        - **æ—¥æœŸ**ï¼šæ”¯æŒåˆ—å `æ—¥æœŸ`ã€`Date`ã€`date`
        - **å•ä½å‡€å€¼**ï¼šæ”¯æŒåˆ—å `å•ä½å‡€å€¼`ã€`å‡€å€¼`ã€`NAV`ã€`nav_value`

        **å¯é€‰åˆ—ï¼š**
        - **ç´¯è®¡å‡€å€¼**ï¼šæ”¯æŒåˆ—å `ç´¯è®¡å‡€å€¼`ã€`ç´¯ç§¯å‡€å€¼`ã€`Cumulative NAV`ã€`cumulative_nav`

        **ç¤ºä¾‹æ ¼å¼ï¼š**
        ```
        æ—¥æœŸ,å•ä½å‡€å€¼,ç´¯è®¡å‡€å€¼
        2024-01-01,1.0000,1.0000
        2024-01-02,1.0012,1.0012
        2024-01-03,0.9998,0.9998
        ```
        """)

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "é€‰æ‹©å‡€å€¼æ•°æ®æ–‡ä»¶",
        type=['csv', 'xlsx', 'xls'],
        key="nav_upload"
    )

    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            else:
                df = pd.read_excel(uploaded_file)

            st.write("**æ–‡ä»¶é¢„è§ˆï¼š**")
            st.dataframe(df.head(10), use_container_width=True)

            st.write("**åˆ—æ˜ å°„æ£€æµ‹ï¼š**")
            column_mapping = detect_and_map_columns(df, 'nav')

            col1, col2 = st.columns(2)
            with col1:
                st.write("åŸå§‹åˆ—å â†’ æ ‡å‡†åˆ—å")
                for orig, mapped in column_mapping.items():
                    st.write(f"`{orig}` â†’ `{mapped}`")

            with col2:
                st.write("æ£€æµ‹ç»“æœ")
                required_found = all(col in column_mapping.values() for col in ['date', 'nav_value'])
                if required_found:
                    st.success("âœ… å¿…éœ€åˆ—æ£€æµ‹æˆåŠŸ")
                else:
                    st.error("âŒ ç¼ºå°‘å¿…éœ€åˆ—")

            if required_found:
                if st.button("ğŸš€ å¯¼å…¥å‡€å€¼æ•°æ®", type="primary"):
                    try:
                        processed_df = process_nav_data(df, column_mapping)
                        success = db.add_nav_data(product_code, processed_df, merge_mode=True)

                        if success:
                            st.success(f"æˆåŠŸå¯¼å…¥ {len(processed_df)} æ¡å‡€å€¼è®°å½•ï¼")
                            st.balloons()
                        else:
                            st.error("å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
                    except Exception as e:
                        st.error(f"æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")

        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")


def render_holdings_import(db):
    """æ¸²æŸ“æŒä»“æ•°æ®å¯¼å…¥"""
    st.subheader("å¯¼å…¥æŒä»“æ•°æ®")

    # äº§å“é€‰æ‹©
    products = db.get_products()
    if not products:
        st.warning("è¯·å…ˆæ·»åŠ äº§å“")
        return

    product_options = {f"{p['product_name']} ({p['product_code']})": p['product_code'] for p in products}
    selected_product = st.selectbox("é€‰æ‹©äº§å“", options=list(product_options.keys()), key="holdings_product")
    product_code = product_options[selected_product]

    # æ•°æ®æ ¼å¼é€‰æ‹©
    st.write("**é€‰æ‹©æ•°æ®æ ¼å¼ï¼š**")
    data_format = st.radio(
        "æŒä»“æ•°æ®æ ¼å¼",
        options=["matrix", "long", "batch_files"],
        format_func=lambda x: "çŸ©é˜µæ ¼å¼ï¼ˆè¡Œ=æ—¥æœŸï¼Œåˆ—=è‚¡ç¥¨ä»£ç ï¼‰" if x == "matrix"
        else "é•¿æ ¼å¼ï¼ˆæ¯è¡Œä¸€æ¡è®°å½•ï¼‰" if x == "long"
        else "æ‰¹é‡æ–‡ä»¶ä¸Šä¼ ",
        index=0,
        key="data_format"
    )

    # æ˜¾ç¤ºæ•°æ®æ ¼å¼è¦æ±‚
    with st.expander("ğŸ“‹ æŸ¥çœ‹æ•°æ®æ ¼å¼è¦æ±‚"):
        if data_format == "matrix":
            st.markdown("""
            **çŸ©é˜µæ ¼å¼è¯´æ˜ï¼š**
            - ç¬¬ä¸€åˆ—ï¼šæ—¥æœŸï¼ˆæ”¯æŒæ ¼å¼ï¼šYYYYMMDDã€YYYY-MM-DDã€YYYY/MM/DDï¼‰
            - å…¶ä»–åˆ—ï¼šè‚¡ç¥¨tickerï¼ˆå¦‚ 123456.SH, 000001.SZ ç­‰ï¼‰
            - å•å…ƒæ ¼å€¼ï¼šè¯¥è‚¡ç¥¨çš„è£¸æƒé‡å€¼ï¼ˆéç™¾åˆ†æ¯”ï¼‰
            - ç³»ç»Ÿä¼šè‡ªåŠ¨è®¡ç®—ç›¸å¯¹æƒé‡ï¼šè£¸å€¼/å½“æ—¥æ‰€æœ‰è‚¡ç¥¨è£¸å€¼ä¹‹å’Œ
            - ç©ºå€¼æˆ–0å€¼ä¼šè¢«è‡ªåŠ¨å¿½ç•¥

            **ç¤ºä¾‹æ ¼å¼ï¼š**
            ```
            æ—¥æœŸ,000001.SZ,600519.SH,600036.SH,000858.SZ
            20240131,1000,2000,1500,800
            20240229,1200,1800,1400,900
            20240331,1100,2100,1600,750
            ```

            **æƒé‡è®¡ç®—ç¤ºä¾‹ï¼š**
            - 20240131å½“æ—¥æ€»è£¸å€¼ï¼š1000+2000+1500+800=5300
            - 000001.SZæƒé‡ï¼š1000/5300â‰ˆ18.87%
            - 600519.SHæƒé‡ï¼š2000/5300â‰ˆ37.74%
            """)
        elif data_format == "long":
            st.markdown("""
            **é•¿æ ¼å¼è¯´æ˜ï¼š**
            - **å¿…éœ€åˆ—ï¼š** æ—¥æœŸã€è‚¡ç¥¨ä»£ç 
            - **å¯é€‰åˆ—ï¼š** è‚¡ç¥¨åç§°ã€æŒä»“æ¯”ä¾‹ã€æŒä»“å¸‚å€¼ã€æŒè‚¡æ•°é‡

            **ç¤ºä¾‹æ ¼å¼ï¼š**
            ```
            æ—¥æœŸ,è‚¡ç¥¨ä»£ç ,è‚¡ç¥¨åç§°,æŒä»“æ¯”ä¾‹
            2024-03-31,600519,è´µå·èŒ…å°,8.5
            2024-03-31,600036,æ‹›å•†é“¶è¡Œ,6.1
            ```
            """)
        else:  # batch_files
            st.markdown("""
            **æ‰¹é‡æ–‡ä»¶ä¸Šä¼ è¯´æ˜ï¼š**
            - å¯ä»¥åŒæ—¶ä¸Šä¼ å¤šä¸ªæŒä»“æ–‡ä»¶
            - ç³»ç»Ÿä¼šè‡ªåŠ¨åŒ¹é…æ–‡ä»¶ä¸­çš„äº§å“åç§°ä¸æ•°æ®åº“ä¸­çš„äº§å“
            - **å¿…éœ€åˆ—ï¼š**
              - **äº§å“åç§°**ï¼šä¸æ•°æ®åº“ä¸­çš„äº§å“åç§°å®Œå…¨åŒ¹é…
              - **æ—¥æœŸ**ï¼šæŒä»“æ—¥æœŸ
              - **è¯åˆ¸ä»£ç **ï¼š6ä½æ•°å­—ä»£ç ï¼ˆå¦‚ 688718ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ·»åŠ äº¤æ˜“æ‰€åç¼€ï¼‰
              - **æŒä»“å¸‚å€¼**ï¼šè¯¥è‚¡ç¥¨çš„å¸‚å€¼
            - **è¯åˆ¸ä»£ç è§„åˆ™**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨æ·»åŠ äº¤æ˜“æ‰€åç¼€
              - 6å¼€å¤´çš„ä»£ç ä¼šæ·»åŠ  .SH åç¼€ï¼ˆä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€ï¼‰
              - å…¶ä»–ä»£ç ä¼šæ·»åŠ  .SZ åç¼€ï¼ˆæ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€ï¼‰

            **ç¤ºä¾‹æ ¼å¼ï¼š**
            ```
            äº§å“åç§°,æ—¥æœŸ,è¯åˆ¸ä»£ç ,æŒä»“å¸‚å€¼
            åŸºé‡‘A,2024-12-31,688718,1000000
            åŸºé‡‘A,2024-12-31,600519,2000000
            ```
            """)

    # æ–‡ä»¶ä¸Šä¼ 
    if data_format == "batch_files":
        uploaded_files = st.file_uploader(
            "é€‰æ‹©å¤šä¸ªæŒä»“æ•°æ®æ–‡ä»¶",
            type=['csv', 'xlsx', 'xls'],
            accept_multiple_files=True,
            key="batch_holdings_upload"
        )

        if uploaded_files:
            st.write(f"**å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶**")

            # å¤„ç†æ‰€æœ‰æ–‡ä»¶
            all_processed_data = []
            file_summary = []

            for uploaded_file in uploaded_files:
                try:
                    # è¯»å–æ–‡ä»¶
                    if uploaded_file.name.endswith('.csv'):
                        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
                    else:
                        df = pd.read_excel(uploaded_file)

                    # æŸ¥æ‰¾å¿…éœ€åˆ—
                    product_col = None
                    date_col = None
                    code_col = None
                    value_col = None

                    for col in df.columns:
                        if 'äº§å“åç§°' in col or 'äº§å“' in col:
                            product_col = col
                        elif 'æ—¥æœŸ' in col or 'Date' in col:
                            date_col = col
                        elif 'è¯åˆ¸ä»£ç ' in col or 'è‚¡ç¥¨ä»£ç ' in col or 'ä»£ç ' in col:
                            code_col = col
                        elif 'æŒä»“å¸‚å€¼' in col or 'å¸‚å€¼' in col:
                            value_col = col

                    if all([product_col, date_col, code_col, value_col]):
                        # å¤„ç†æ•°æ®
                        processed_df = df[[product_col, date_col, code_col, value_col]].copy()
                        processed_df.columns = ['product_name', 'date', 'stock_code', 'market_value']

                        # æ•°æ®æ¸…ç†
                        processed_df['date'] = pd.to_datetime(processed_df['date']).dt.strftime('%Y-%m-%d')
                        processed_df['stock_code'] = processed_df['stock_code'].astype(str).str.zfill(6)

                        # æ·»åŠ äº¤æ˜“æ‰€åç¼€ï¼š6å¼€å¤´çš„æ˜¯ä¸Šæµ·(.SH)ï¼Œå…¶ä»–æ˜¯æ·±åœ³(.SZ)
                        def add_exchange_suffix(code):
                            code = str(code).zfill(6)  # ç¡®ä¿æ˜¯6ä½æ•°å­—
                            if code.startswith('6'):
                                return f"{code}.SH"
                            else:
                                return f"{code}.SZ"

                        processed_df['stock_code'] = processed_df['stock_code'].apply(add_exchange_suffix)
                        processed_df['market_value'] = pd.to_numeric(processed_df['market_value'], errors='coerce')

                        # åˆ é™¤æ— æ•ˆæ•°æ®
                        processed_df = processed_df.dropna(subset=['product_name', 'stock_code', 'market_value'])
                        processed_df = processed_df[processed_df['market_value'] > 0]

                        # æ·»åŠ å…¶ä»–å¿…éœ€åˆ—
                        processed_df['stock_name'] = ''  # è‚¡ç¥¨åç§°ç•™ç©º
                        processed_df['position_ratio'] = None  # ç¨åè®¡ç®—
                        processed_df['shares'] = None

                        all_processed_data.append(processed_df)

                        # æ–‡ä»¶æ‘˜è¦
                        unique_products = processed_df['product_name'].nunique()
                        unique_dates = processed_df['date'].nunique()
                        stock_count = len(processed_df)

                        file_summary.append({
                            'filename': uploaded_file.name,
                            'products': unique_products,
                            'dates': unique_dates,
                            'records': stock_count,
                            'status': 'âœ… æˆåŠŸ'
                        })
                    else:
                        missing_cols = []
                        if not product_col: missing_cols.append('äº§å“åç§°')
                        if not date_col: missing_cols.append('æ—¥æœŸ')
                        if not code_col: missing_cols.append('è¯åˆ¸ä»£ç ')
                        if not value_col: missing_cols.append('æŒä»“å¸‚å€¼')

                        file_summary.append({
                            'filename': uploaded_file.name,
                            'products': 0,
                            'dates': 0,
                            'records': 0,
                            'status': f'âŒ ç¼ºå°‘åˆ—: {", ".join(missing_cols)}'
                        })

                except Exception as e:
                    file_summary.append({
                        'filename': uploaded_file.name,
                        'products': 0,
                        'dates': 0,
                        'records': 0,
                        'status': f'âŒ å¤„ç†å¤±è´¥: {str(e)}'
                    })

            # æ˜¾ç¤ºæ–‡ä»¶å¤„ç†æ‘˜è¦
            st.write("**æ–‡ä»¶å¤„ç†æ‘˜è¦ï¼š**")
            summary_df = pd.DataFrame(file_summary)
            st.dataframe(summary_df, use_container_width=True, hide_index=True)

            if all_processed_data:
                # åˆå¹¶æ‰€æœ‰æ•°æ®
                combined_df = pd.concat(all_processed_data, ignore_index=True)

                # æŒ‰äº§å“åˆ†ç»„å¹¶è®¡ç®—æƒé‡
                for product_name in combined_df['product_name'].unique():
                    product_mask = combined_df['product_name'] == product_name
                    product_data = combined_df[product_mask]

                    # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—æƒé‡
                    for date in product_data['date'].unique():
                        date_mask = (combined_df['product_name'] == product_name) & (combined_df['date'] == date)
                        date_data = combined_df[date_mask]
                        total_value = date_data['market_value'].sum()

                        if total_value > 0:
                            combined_df.loc[date_mask, 'position_ratio'] = (date_data[
                                                                                'market_value'] / total_value) * 100

                # æ˜¾ç¤ºå¤„ç†ç»“æœ
                st.write("**å¤„ç†ç»“æœæ¦‚è§ˆï¼š**")
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("æ€»è®°å½•æ•°", len(combined_df))

                with col2:
                    st.metric("æ¶‰åŠäº§å“", combined_df['product_name'].nunique())

                with col3:
                    st.metric("æ¶‰åŠæ—¥æœŸ", combined_df['date'].nunique())

                # æ˜¾ç¤ºè¯åˆ¸ä»£ç è½¬æ¢ç¤ºä¾‹
                st.write("**è¯åˆ¸ä»£ç è½¬æ¢ç¤ºä¾‹ï¼š**")
                sample_codes = combined_df['stock_code'].drop_duplicates().head(10)
                code_examples = []
                for code in sample_codes:
                    original = code.replace('.SH', '').replace('.SZ', '')
                    code_examples.append({
                        'åŸå§‹ä»£ç ': original,
                        'è½¬æ¢åä»£ç ': code,
                        'äº¤æ˜“æ‰€': 'ä¸Šæµ·' if code.endswith('.SH') else 'æ·±åœ³'
                    })

                if code_examples:
                    st.dataframe(pd.DataFrame(code_examples), use_container_width=True, hide_index=True)

                # äº§å“åŒ¹é…æ£€æŸ¥
                st.write("**äº§å“åŒ¹é…æ£€æŸ¥ï¼š**")
                db_product_names = [p['product_name'] for p in db.get_products()]
                matched_products = []
                unmatched_products = []

                for product in combined_df['product_name'].unique():
                    if product in db_product_names:
                        matched_products.append(product)
                        st.success(f"âœ… {product}")
                    else:
                        unmatched_products.append(product)
                        st.error(f"âŒ {product} (æ•°æ®åº“ä¸­ä¸å­˜åœ¨)")

                if matched_products:
                    # åªå¯¼å…¥åŒ¹é…çš„äº§å“æ•°æ®
                    matched_df = combined_df[combined_df['product_name'].isin(matched_products)]

                    st.write("**æ•°æ®é¢„è§ˆï¼š**")
                    st.dataframe(matched_df.head(10), use_container_width=True)

                    if st.button("ğŸš€ æ‰¹é‡å¯¼å…¥æŒä»“æ•°æ®", type="primary"):
                        try:
                            total_imported = 0

                            for product_name in matched_products:
                                product_data = matched_df[matched_df['product_name'] == product_name]

                                # è·å–å¯¹åº”çš„äº§å“ä»£ç 
                                db_products = db.get_products()
                                product_code_batch = None
                                for p in db_products:
                                    if p['product_name'] == product_name:
                                        product_code_batch = p['product_code']
                                        break

                                if product_code_batch:
                                    success = db.add_holdings_data(product_code_batch, product_data)
                                    if success:
                                        total_imported += len(product_data)

                            st.success(f"æ‰¹é‡å¯¼å…¥å®Œæˆï¼æ€»å…±å¯¼å…¥ {total_imported} æ¡è®°å½•")
                            st.balloons()

                        except Exception as e:
                            st.error(f"æ‰¹é‡å¯¼å…¥å¤±è´¥ï¼š{str(e)}")
                else:
                    st.warning("æ²¡æœ‰åŒ¹é…çš„äº§å“å¯ä»¥å¯¼å…¥")

    else:
        # å•æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æŒä»“æ•°æ®æ–‡ä»¶",
            type=['csv', 'xlsx', 'xls'],
            key="holdings_upload"
        )

        if uploaded_file is not None:
            try:
                # è¯»å–æ–‡ä»¶
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
                else:
                    df = pd.read_excel(uploaded_file)

                st.write("**æ–‡ä»¶é¢„è§ˆï¼š**")
                st.dataframe(df.head(10), use_container_width=True)

                # æ ¹æ®æ ¼å¼è¿›è¡Œä¸åŒçš„å¤„ç†
                if data_format == "matrix":
                    st.write("**çŸ©é˜µæ ¼å¼æ£€æµ‹ï¼š**")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("æ•°æ®ç»“æ„")
                        st.info(f"æ£€æµ‹åˆ° {len(df)} ä¸ªæ—¥æœŸ")
                        st.info(f"æ£€æµ‹åˆ° {len(df.columns) - 1} åªè‚¡ç¥¨")

                    with col2:
                        st.write("è‚¡ç¥¨ä»£ç åˆ—è¡¨")
                        stock_codes = df.columns[1:].tolist()  # é™¤ç¬¬ä¸€åˆ—ï¼ˆæ—¥æœŸï¼‰å¤–çš„æ‰€æœ‰åˆ—
                        st.write(stock_codes[:10])  # æ˜¾ç¤ºå‰10ä¸ª
                        if len(stock_codes) > 10:
                            st.write(f"... è¿˜æœ‰ {len(stock_codes) - 10} åªè‚¡ç¥¨")

                    # å¯¼å…¥æŒ‰é’®
                    if st.button("ğŸš€ å¯¼å…¥æŒä»“æ•°æ®ï¼ˆçŸ©é˜µæ ¼å¼ï¼‰", type="primary"):
                        try:
                            processed_df = process_holdings_data(df, {}, data_format='matrix')
                            success = db.add_holdings_data(product_code, processed_df)

                            if success:
                                unique_dates = processed_df['date'].nunique()
                                unique_stocks = processed_df['stock_code'].nunique()
                                st.success(f"æˆåŠŸå¯¼å…¥ {len(processed_df)} æ¡æŒä»“è®°å½•ï¼")
                                st.info(f"åŒ…å« {unique_dates} ä¸ªæ—¥æœŸï¼Œ{unique_stocks} åªè‚¡ç¥¨")
                                st.balloons()
                            else:
                                st.error("å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
                        except Exception as e:
                            st.error(f"æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")
                            import traceback
                            st.code(traceback.format_exc())

                else:
                    # é•¿æ ¼å¼å¤„ç†
                    st.write("**åˆ—æ˜ å°„æ£€æµ‹ï¼š**")
                    column_mapping = detect_and_map_columns(df, 'holdings')

                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("åŸå§‹åˆ—å â†’ æ ‡å‡†åˆ—å")
                        for orig, mapped in column_mapping.items():
                            st.write(f"`{orig}` â†’ `{mapped}`")

                    with col2:
                        st.write("æ£€æµ‹ç»“æœ")
                        required_found = all(col in column_mapping.values() for col in ['date', 'stock_code'])
                        if required_found:
                            st.success("âœ… å¿…éœ€åˆ—æ£€æµ‹æˆåŠŸ")
                            unique_dates = df[list(column_mapping.keys())[0]].nunique() if column_mapping else 0
                            st.info(f"åŒ…å« {unique_dates} ä¸ªä¸åŒæ—¥æœŸçš„æŒä»“æ•°æ®")
                        else:
                            st.error("âŒ ç¼ºå°‘å¿…éœ€åˆ—")

                    # å¯¼å…¥æŒ‰é’®
                    if required_found:
                        if st.button("ğŸš€ å¯¼å…¥æŒä»“æ•°æ®ï¼ˆé•¿æ ¼å¼ï¼‰", type="primary"):
                            try:
                                processed_df = process_holdings_data(df, column_mapping, data_format='long')
                                success = db.add_holdings_data(product_code, processed_df)

                                if success:
                                    st.success(f"æˆåŠŸå¯¼å…¥ {len(processed_df)} æ¡æŒä»“è®°å½•ï¼")
                                    st.balloons()
                                else:
                                    st.error("å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
                            except Exception as e:
                                st.error(f"æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")

            except Exception as e:
                st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")