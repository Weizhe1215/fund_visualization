"""
å®æ—¶æŒä»“çƒ­åŠ›å›¾ç»„ä»¶
"""
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import os
import glob
from datetime import datetime, timedelta
import time
import numpy as np
import plotly.figure_factory as ff

# å›ºå®šæ•°æ®è·¯å¾„
BASE_DATA_PATH = r"C:\shared_data\å®ç›˜\äº¤æ˜“æ•°æ®å®šé¢‘å¯¼å‡º"


def create_heatmap_data(df, mode='price_change'):
    """åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®"""
    if df.empty:
        return None, None, None, None

    # è®¡ç®—æƒé‡ï¼ˆåŸºäºå¸‚å€¼ï¼‰
    df['weight'] = df['market_value'] / df['market_value'].sum() * 100

    # åˆ†ä¸ºæ¶¨è·Œä¸¤ç»„
    rising_df = df[df['change_pct'] > 0].copy()
    falling_df = df[df['change_pct'] < 0].copy()

    if mode == 'price_change':
        # æ¨¡å¼1ï¼šçº¯æ¶¨è·Œå¹…ï¼Œé¢ç§¯å®Œå…¨åŸºäºæ¶¨è·Œå¹…å¤§å°
        if not rising_df.empty:
            # é¢ç§¯ = æ¶¨è·Œå¹…çš„å¹³æ–¹ï¼ˆæ”¾å¤§å·®å¼‚ï¼‰
            rising_df['size'] = rising_df['change_pct'] ** 2
            rising_df['color_value'] = rising_df['change_pct']

        if not falling_df.empty:
            # é¢ç§¯ = è·Œå¹…çš„å¹³æ–¹
            falling_df['size'] = falling_df['change_pct'] ** 2  # è´Ÿæ•°çš„å¹³æ–¹è¿˜æ˜¯æ­£æ•°
            falling_df['color_value'] = falling_df['change_pct']

        title_rising = "ä¸Šæ¶¨è‚¡ç¥¨çƒ­åŠ›å›¾ï¼ˆé¢ç§¯=æ¶¨å¹…ï¼‰"
        title_falling = "ä¸‹è·Œè‚¡ç¥¨çƒ­åŠ›å›¾ï¼ˆé¢ç§¯=è·Œå¹…ï¼‰"
        color_title = "æ¶¨è·Œå¹… (%)"
    else:
        # æ¨¡å¼2ï¼šæ”¶ç›Šè´¡çŒ®ï¼Œé¢ç§¯åŸºäºè´¡çŒ®åº¦
        # å…ˆè®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„åŸå§‹è´¡çŒ®åº¦
        df['raw_contribution'] = df['change_pct'] * df['weight'] / 100
        total_abs_contribution = df['raw_contribution'].abs().sum()

        # å½’ä¸€åŒ–è´¡çŒ®åº¦
        if total_abs_contribution > 0:
            df['contribution'] = (df['raw_contribution'].abs() / total_abs_contribution) * 100
            df['contribution_signed'] = df['raw_contribution'] / total_abs_contribution * 100  # ä¿ç•™æ­£è´Ÿå·ç”¨äºé¢œè‰²
        else:
            df['contribution'] = 0
            df['contribution_signed'] = 0

        # é‡æ–°åˆ†ç»„
        rising_df = df[df['change_pct'] > 0].copy() if not df[df['change_pct'] > 0].empty else pd.DataFrame()
        falling_df = df[df['change_pct'] < 0].copy() if not df[df['change_pct'] < 0].empty else pd.DataFrame()

        if not rising_df.empty:
            rising_df['size'] = rising_df['contribution']  # é¢ç§¯ = å½’ä¸€åŒ–è´¡çŒ®åº¦
            rising_df['color_value'] = rising_df['contribution_signed']  # é¢œè‰² = å¸¦ç¬¦å·çš„è´¡çŒ®åº¦

        if not falling_df.empty:
            falling_df['size'] = falling_df['contribution']  # é¢ç§¯ = å½’ä¸€åŒ–è´¡çŒ®åº¦
            falling_df['color_value'] = falling_df['contribution_signed']  # é¢œè‰² = å¸¦ç¬¦å·çš„è´¡çŒ®åº¦

        title_rising = "æ­£è´¡çŒ®è‚¡ç¥¨çƒ­åŠ›å›¾ï¼ˆé¢ç§¯=è´¡çŒ®åº¦ï¼‰"
        title_falling = "è´Ÿè´¡çŒ®è‚¡ç¥¨çƒ­åŠ›å›¾ï¼ˆé¢ç§¯=è´¡çŒ®åº¦ï¼‰"
        color_title = "è´¡çŒ®åº¦ (%)"

    return rising_df, falling_df, (title_rising, title_falling), color_title


def render_dual_treemap_heatmap(rising_df, falling_df, titles, color_title, mode='price_change'):
    """æ¸²æŸ“åŒçƒ­åŠ›å›¾ï¼ˆæ¶¨è·Œåˆ†å¼€ï¼‰"""
    title_rising, title_falling = titles

    col1, col2 = st.columns(2)

    with col1:
        st.subheader(title_rising)
        if rising_df is not None and not rising_df.empty:
            render_single_treemap(rising_df, color_title, 'Reds', mode)
        else:
            st.info("æš‚æ— ä¸Šæ¶¨è‚¡ç¥¨")

    with col2:
        st.subheader(title_falling)
        if falling_df is not None and not falling_df.empty:
            render_single_treemap(falling_df, color_title, 'Greens_r', mode)
        else:
            st.info("æš‚æ— ä¸‹è·Œè‚¡ç¥¨")


def render_single_treemap(df, color_title, colorscale, mode='price_change'):
    """æ¸²æŸ“å•ä¸ªçƒ­åŠ›å›¾"""
    # æ ¹æ®æ¨¡å¼å‡†å¤‡ä¸åŒçš„æ˜¾ç¤ºæ ‡ç­¾
    if 'contribution' in df.columns:  # è´¡çŒ®åº¦æ¨¡å¼
        df['label'] = df.apply(lambda x: f"{x['stock_name']}<br>{x['stock_code']}<br>{x['contribution']:.3f}%", axis=1)
    else:  # ä»·æ ¼æ¶¨è·Œæ¨¡å¼
        df['label'] = df.apply(lambda x: f"{x['stock_name']}<br>{x['stock_code']}<br>{x['change_pct']:.2f}%", axis=1)

    # ä¸ºä¸Šæ¶¨å’Œä¸‹è·Œä½¿ç”¨ä¸åŒçš„é«˜çº§é…è‰²
    if colorscale == 'Reds':
        colorscale = 'Reds'  # ä¿æŒçº¢è‰²ç³»
    elif colorscale == 'Greens_r':
        colorscale = 'Greens'  # æ”¹ä¸ºæ­£å‘ç»¿è‰²ç³»

    fig = go.Figure(go.Treemap(
        labels=df['label'],
        values=df['size'],
        parents=[""] * len(df),
        marker=dict(
            colorscale=colorscale,
            colorbar=dict(title=color_title),
            colors=df['color_value'],
            line=dict(width=2, color='rgba(255,255,255,0.3)')  # æ·»åŠ è¾¹æ¡†çº¿
        ),
        textinfo="label",
        textfont_size=11,
        hovertemplate='<b>%{label}</b><br>' +
                      f'{color_title}: %{{color:.2f}}<br>' +
                      'é¢ç§¯æƒé‡: %{value:.2f}<br>' +
                      '<extra></extra>'
    ))

    fig.update_layout(
        height=400,
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        margin=dict(t=20, b=20, l=20, r=20)
    )

    st.plotly_chart(fig, use_container_width=True)


def get_latest_holding_files():
    """è·å–æ¯ä¸ªäº§å“æœ€æ–°çš„æŒä»“æ–‡ä»¶"""
    try:
        if not os.path.exists(BASE_DATA_PATH):
            return {}

        # è·å–æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹å¹¶æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
        date_folders = [f for f in os.listdir(BASE_DATA_PATH)
                        if f.isdigit() and len(f) == 8 and os.path.isdir(os.path.join(BASE_DATA_PATH, f))]

        if not date_folders:
            return {}

        latest_date_folder = max(date_folders)
        date_folder_path = os.path.join(BASE_DATA_PATH, latest_date_folder)

        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰æŒä»“æ–‡ä»¶
        all_files = []
        for root, dirs, files in os.walk(date_folder_path):
            for file in files:
                if file.startswith("å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º") and (file.endswith('.xlsx') or file.endswith('.csv')):
                    all_files.append(os.path.join(root, file))

        # æŒ‰äº§å“åˆ†ç»„æ–‡ä»¶
        product_files = {}
        for file_path in all_files:
            filename = os.path.basename(file_path)
            # è§£ææ–‡ä»¶åï¼šå•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º_ä¸œè´¢EMC_æ™®é€š_20250625-123500
            # æˆ–ï¼šå•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º_å¼€æºATX_æ™®é€š1_20250625-121200

            # ç§»é™¤å‰ç¼€
            name_part = filename.replace('å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º_', '').replace('å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º-', '')

            # åˆ†å‰²è·å–äº§å“æ ‡è¯†å’Œæ—¶é—´
            parts = name_part.split('_')
            if len(parts) >= 2:
                # æœ€åä¸€éƒ¨åˆ†åŒ…å«æ—¥æœŸæ—¶é—´
                datetime_part = parts[-1]
                # äº§å“æ ‡è¯†æ˜¯é™¤äº†æœ€åä¸€éƒ¨åˆ†çš„å…¶ä»–éƒ¨åˆ†
                product_identifier = '_'.join(parts[:-1])

                # æå–æ—¶é—´æˆ³
                if '-' in datetime_part:
                    date_time = datetime_part.replace('.xlsx', '').replace('.csv', '')
                    try:
                        timestamp = datetime.strptime(date_time, "%Y%m%d-%H%M%S")
                    except:
                        continue
                else:
                    continue

                if product_identifier not in product_files:
                    product_files[product_identifier] = []

                product_files[product_identifier].append({
                    'file_path': file_path,
                    'timestamp': timestamp,
                    'filename': filename
                })

        # è·å–æ¯ä¸ªäº§å“æœ€æ–°çš„æ–‡ä»¶
        latest_files = {}
        for product_id, files_list in product_files.items():
            if files_list:
                latest_file = max(files_list, key=lambda x: x['timestamp'])
                latest_files[product_id] = latest_file['file_path']

        return {
            'latest_date': latest_date_folder,
            'files': latest_files,
            'file_count': sum(len(files) for files in product_files.values())
        }

    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å¤¹å¤±è´¥: {e}")
        return {}


def read_holding_file(file_path):
    """è¯»å–å•ä¸ªæŒä»“æ–‡ä»¶"""
    try:
        if file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        else:
            df = pd.read_csv(file_path, encoding='utf-8-sig')

        # æ ‡å‡†åŒ–åˆ—åï¼Œé¿å…é‡å¤
        column_mapping = {}
        used_standard_names = set()

        for col in df.columns:
            if 'äº§å“åç§°' in col and 'product_name' not in used_standard_names:
                column_mapping[col] = 'product_name'
                used_standard_names.add('product_name')
            elif 'è¯åˆ¸ä»£ç ' in col and 'stock_code' not in used_standard_names:
                column_mapping[col] = 'stock_code'
                used_standard_names.add('stock_code')
            elif 'è¯åˆ¸åç§°' in col and 'stock_name' not in used_standard_names:
                column_mapping[col] = 'stock_name'
                used_standard_names.add('stock_name')
            elif 'æŒä»“å¸‚å€¼' in col and 'market_value' not in used_standard_names:
                column_mapping[col] = 'market_value'
                used_standard_names.add('market_value')
            elif ('æ¶¨è·Œå¹…' in col or 'å½“æ—¥æ¶¨è·Œå¹…' in col) and 'change_pct' not in used_standard_names:
                column_mapping[col] = 'change_pct'
                used_standard_names.add('change_pct')
            elif 'æ—¥æœŸ' in col and 'date' not in used_standard_names:
                column_mapping[col] = 'date'
                used_standard_names.add('date')

        # åº”ç”¨åˆ—åæ˜ å°„
        df = df.rename(columns=column_mapping)

        # æ£€æŸ¥å¿…éœ€åˆ—
        required_cols = ['product_name', 'stock_code', 'stock_name', 'market_value', 'change_pct']
        missing_cols = [col for col in required_cols if col not in df.columns]

        if missing_cols:
            st.warning(f"æ–‡ä»¶ {os.path.basename(file_path)} ç¼ºå°‘åˆ—: {missing_cols}")
            st.write(f"å®é™…åˆ—å: {list(df.columns)}")
            return pd.DataFrame()

        # æ•°æ®ç±»å‹è½¬æ¢
        df['stock_code'] = df['stock_code'].astype(str).str.zfill(6)
        df['market_value'] = pd.to_numeric(df['market_value'], errors='coerce')
        df['change_pct'] = pd.to_numeric(df['change_pct'], errors='coerce')

        # åˆ é™¤æ— æ•ˆæ•°æ®
        df = df.dropna(subset=['market_value', 'change_pct'])
        df = df[df['market_value'] > 0]

        return df

    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return pd.DataFrame()


def render_realtime_heatmap(db):
    """æ¸²æŸ“å®æ—¶æŒä»“çƒ­åŠ›å›¾é¡µé¢"""
    st.header("ğŸ“Š å®æ—¶æŒä»“çƒ­åŠ›å›¾")

    # æ˜¾ç¤ºæ•°æ®è·¯å¾„
    st.info(f"æ•°æ®è·¯å¾„: {BASE_DATA_PATH}")

    # æ·»åŠ åˆ·æ–°æŒ‰é’®å’Œè‡ªåŠ¨åˆ·æ–°
    col1, col2, col3 = st.columns([1, 1, 2])

    with col1:
        if st.button("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°", type="primary"):
            st.rerun()

    with col2:
        auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–° (5åˆ†é’Ÿ)", value=False)

    with col3:
        last_update = st.empty()

    # è·å–æœ€æ–°æ–‡ä»¶
    file_info = get_latest_holding_files()

    if not file_info or not file_info.get('files'):
        st.error("æœªæ‰¾åˆ°æŒä»“æ–‡ä»¶")
        return

    st.success(
        f"æœ€æ–°æ—¥æœŸ: {file_info['latest_date']}, æ€»æ–‡ä»¶æ•°: {file_info.get('file_count', 0)}, äº§å“æ•°: {len(file_info['files'])}")

    # è·å–æ•°æ®åº“ä¸­çš„äº§å“åˆ—è¡¨
    db_products = db.get_products()
    db_product_names = {p['product_name']: p['product_code'] for p in db_products}

    # è¯»å–æ¯ä¸ªäº§å“çš„æœ€æ–°æ–‡ä»¶æ•°æ®å¹¶åŒ¹é…äº§å“
    all_data = {}
    matched_products = []

    for product_id, file_path in file_info['files'].items():
        df = read_holding_file(file_path)
        if not df.empty and 'product_name' in df.columns:
            # è·å–æ–‡ä»¶ä¸­çš„äº§å“åç§°
            file_product_names = df['product_name'].unique()

            for prod_name in file_product_names:
                # å°è¯•åŒ¹é…æ•°æ®åº“ä¸­çš„äº§å“
                if prod_name in db_product_names:
                    product_data = df[df['product_name'] == prod_name].copy()
                    if not product_data.empty:
                        # å¦‚æœäº§å“å·²å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
                        if prod_name in all_data:
                            # åˆå¹¶æŒä»“æ•°æ®ï¼ŒæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„ï¼Œå¸‚å€¼ç›¸åŠ ï¼Œæ¶¨è·Œå¹…å–å¹³å‡
                            existing_data = all_data[prod_name]
                            combined_data = pd.concat([existing_data, product_data], ignore_index=True)

                            # æŒ‰è‚¡ç¥¨ä»£ç åˆå¹¶
                            merged_data = combined_data.groupby('stock_code').agg({
                                'stock_name': 'first',  # å–ç¬¬ä¸€ä¸ªåç§°
                                'market_value': 'sum',  # å¸‚å€¼ç›¸åŠ 
                                'change_pct': 'mean',  # æ¶¨è·Œå¹…å–å¹³å‡
                                'product_name': 'first'
                            }).reset_index()

                            all_data[prod_name] = merged_data
                        else:
                            all_data[prod_name] = product_data
                            matched_products.append(prod_name)

    if not matched_products:
        st.warning("æœªæ‰¾åˆ°ä¸æ•°æ®åº“åŒ¹é…çš„äº§å“æ•°æ®")
        st.info("è¯·ç¡®ä¿æ–‡ä»¶ä¸­çš„äº§å“åç§°ä¸æ•°æ®åº“ä¸­çš„äº§å“åç§°ä¸€è‡´")
        return

    # äº§å“é€‰æ‹©ä¸‹æ‹‰æ¡†
    selected_product_name = st.selectbox(
        "é€‰æ‹©è¦åˆ†æçš„äº§å“",
        options=matched_products,
        key="realtime_product_selector"
    )

    if selected_product_name and selected_product_name in all_data:
        product_data = all_data[selected_product_name]

        # æ˜¾ç¤ºæ•°æ®æ¦‚å†µ
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æŒä»“è‚¡ç¥¨æ•°", len(product_data))

        with col2:
            total_value = product_data['market_value'].sum()
            st.metric("æ€»å¸‚å€¼", f"{total_value:,.0f}")

        with col3:
            # ä½¿ç”¨æŒä»“æ–‡ä»¶è®¡ç®—å‡†ç¡®çš„å½“æ—¥æ”¶ç›Šç‡
            actual_return = get_product_return_from_holdings(selected_product_name)
            if actual_return is not None:
                st.metric("å½“æ—¥æ”¶ç›Šç‡", f"{actual_return:.2f}%")
            else:
                st.metric("å½“æ—¥æ”¶ç›Šç‡", "è®¡ç®—å¤±è´¥")

        with col4:
            positive_count = len(product_data[product_data['change_pct'] > 0])
            st.metric("ä¸Šæ¶¨è‚¡ç¥¨æ•°", f"{positive_count}/{len(product_data)}")

        # çƒ­åŠ›å›¾å±•ç¤º
        st.divider()
        st.subheader("æŒä»“çƒ­åŠ›å›¾")

        # æ¨¡å¼åˆ‡æ¢
        col1, col2 = st.columns(2)
        with col1:
            heatmap_mode = st.radio(
                "çƒ­åŠ›å›¾æ¨¡å¼",
                options=['price_change', 'contribution'],
                format_func=lambda x: "ä»·æ ¼æ¶¨è·Œ" if x == 'price_change' else "æ”¶ç›Šè´¡çŒ®",
                key="heatmap_mode"
            )

        # ç”Ÿæˆçƒ­åŠ›å›¾æ•°æ®
        rising_df, falling_df, titles, color_title = create_heatmap_data(product_data, heatmap_mode)

        # æ¸²æŸ“çƒ­åŠ›å›¾
        if rising_df is not None or falling_df is not None:
            render_dual_treemap_heatmap(rising_df, falling_df, titles, color_title, heatmap_mode)

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.subheader("è¯¦ç»†ç»Ÿè®¡")

            col1, col2 = st.columns(2)

            with col1:
                st.write("**æ¶¨å¹…å‰5å:**")
                if rising_df is not None and not rising_df.empty:
                    top_gainers = rising_df.nlargest(5, 'change_pct')[['stock_name', 'change_pct', 'weight']]
                    top_gainers['change_pct'] = top_gainers['change_pct'].apply(lambda x: f"{x:.2f}%")
                    top_gainers['weight'] = top_gainers['weight'].apply(lambda x: f"{x:.2f}%")
                    top_gainers.columns = ['è‚¡ç¥¨åç§°', 'æ¶¨è·Œå¹…', 'æƒé‡']
                    st.dataframe(top_gainers, use_container_width=True, hide_index=True)
                else:
                    st.info("æš‚æ— ä¸Šæ¶¨è‚¡ç¥¨")

            with col2:
                st.write("**è·Œå¹…å‰5å:**")
                if falling_df is not None and not falling_df.empty:
                    top_losers = falling_df.nsmallest(5, 'change_pct')[['stock_name', 'change_pct', 'weight']]
                    top_losers['change_pct'] = top_losers['change_pct'].apply(lambda x: f"{x:.2f}%")
                    top_losers['weight'] = top_losers['weight'].apply(lambda x: f"{x:.2f}%")
                    top_losers.columns = ['è‚¡ç¥¨åç§°', 'æ¶¨è·Œå¹…', 'æƒé‡']
                    st.dataframe(top_losers, use_container_width=True, hide_index=True)
                else:
                    st.info("æš‚æ— ä¸‹è·Œè‚¡ç¥¨")

            # æ•°æ®é¢„è§ˆè¡¨æ ¼ï¼ˆç§»åˆ°æœ€åï¼‰
            st.divider()
            st.subheader("æ•°æ®é¢„è§ˆ")
            display_df = product_data[['stock_name', 'stock_code', 'change_pct', 'market_value']].copy()
            display_df['change_pct'] = display_df['change_pct'].apply(lambda x: f"{x:.2f}%")
            display_df['market_value'] = display_df['market_value'].apply(lambda x: f"{x:,.0f}")
            display_df.columns = ['è‚¡ç¥¨åç§°', 'è‚¡ç¥¨ä»£ç ', 'æ¶¨è·Œå¹…', 'å¸‚å€¼']
            #st.dataframe(display_df, use_container_width=True, hide_index=True)

    # è‡ªåŠ¨åˆ·æ–°é€»è¾‘
    if auto_refresh:
        time.sleep(300)  # 5åˆ†é’Ÿ
        st.rerun()

    last_update.write(f"æœ€åæ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def get_latest_asset_files():
    """è·å–æœ€æ–°çš„èµ„äº§å¯¼å‡ºæ–‡ä»¶"""
    try:
        if not os.path.exists(BASE_DATA_PATH):
            return {}

        # è·å–æœ€æ–°æ—¥æœŸæ–‡ä»¶å¤¹
        date_folders = [f for f in os.listdir(BASE_DATA_PATH)
                        if f.isdigit() and len(f) == 8 and os.path.isdir(os.path.join(BASE_DATA_PATH, f))]

        if not date_folders:
            return {}

        latest_date_folder = max(date_folders)
        date_folder_path = os.path.join(BASE_DATA_PATH, latest_date_folder)

        # æŸ¥æ‰¾èµ„äº§å¯¼å‡ºæ–‡ä»¶
        asset_files = []
        for root, dirs, files in os.walk(date_folder_path):
            for file in files:
                if file.startswith("å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º_") and (file.endswith('.xlsx') or file.endswith('.csv')):
                    asset_files.append(os.path.join(root, file))

        # æ‰¾åˆ°æœ€æ–°æ—¶é—´çš„æ–‡ä»¶
        latest_asset_file = None
        latest_time = None

        for file_path in asset_files:
            filename = os.path.basename(file_path)
            # è§£ææ—¶é—´ï¼šå•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º_20250626-161500
            time_part = filename.replace('å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º_', '').replace('.xlsx', '').replace('.csv', '')
            try:
                file_time = datetime.strptime(time_part, "%Y%m%d-%H%M%S")
                if latest_time is None or file_time > latest_time:
                    latest_time = file_time
                    latest_asset_file = file_path
            except:
                continue

        return latest_asset_file

    except Exception as e:
        print(f"è¯»å–èµ„äº§æ–‡ä»¶å¤±è´¥: {e}")
        return None


def read_asset_file(file_path):
    """è¯»å–èµ„äº§å¯¼å‡ºæ–‡ä»¶"""
    try:
        if file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        else:
            df = pd.read_csv(file_path, encoding='utf-8-sig')

        # æŸ¥æ‰¾éœ€è¦çš„åˆ—
        product_col = None
        profit_col = None
        asset_col = None

        for col in df.columns:
            if 'äº§å“åç§°' in col:
                product_col = col
            elif 'å½“æ—¥ç›ˆäº' in col:
                profit_col = col
            elif 'æ€»èµ„äº§' in col:
                asset_col = col

        if not all([product_col, profit_col, asset_col]):
            return pd.DataFrame()

        # æå–éœ€è¦çš„æ•°æ®
        result_df = df[[product_col, profit_col, asset_col]].copy()
        result_df.columns = ['product_name', 'daily_profit', 'total_asset']

        # æ•°æ®ç±»å‹è½¬æ¢
        result_df['daily_profit'] = pd.to_numeric(result_df['daily_profit'], errors='coerce')
        result_df['total_asset'] = pd.to_numeric(result_df['total_asset'], errors='coerce')

        # è®¡ç®—å½“æ—¥æ”¶ç›Šç‡
        result_df['daily_return'] = (result_df['daily_profit'] / result_df['total_asset'] * 100).fillna(0)

        return result_df

    except Exception as e:
        print(f"è¯»å–èµ„äº§æ–‡ä»¶å¤±è´¥: {e}")
        return pd.DataFrame()


def get_product_return_from_holdings(product_name):
    """ä»èµ„äº§æ–‡ä»¶è·å–äº§å“æ”¶ç›Šç‡ï¼ˆåŒ…å«æœŸè´§ï¼‰"""
    try:
        base_path = r"C:\shared_data\å®ç›˜\äº¤æ˜“æ•°æ®å®šé¢‘å¯¼å‡º"

        if not os.path.exists(base_path):
            return None

        # è·å–æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹å¹¶æ’åº
        all_items = os.listdir(base_path)
        date_folders = [f for f in all_items
                        if f.isdigit() and len(f) == 8 and os.path.isdir(os.path.join(base_path, f))]

        if len(date_folders) < 2:
            return None

        date_folders.sort(reverse=True)
        today_folder = date_folders[0]
        yesterday_folder = date_folders[1]

        # è·å–ä»Šå¤©çš„æ•°æ®
        today_assets = get_latest_asset_data_by_folder(base_path, today_folder)
        today_futures = get_latest_futures_data_by_date(today_folder)

        # è·å–æ˜¨å¤©çš„æ•°æ®
        yesterday_assets = get_latest_asset_data_by_folder(base_path, yesterday_folder)
        yesterday_futures = get_latest_futures_data_by_date(yesterday_folder)

        # åˆå¹¶ç°è´§å’ŒæœŸè´§æ•°æ®
        from components.product_returns import combine_assets_and_futures

        today_combined = combine_assets_and_futures(today_assets, today_futures)
        yesterday_combined = combine_assets_and_futures(yesterday_assets, yesterday_futures)

        if today_combined is None or yesterday_combined is None:
            return None

        # æŸ¥æ‰¾äº§å“
        today_product = today_combined[today_combined['äº§å“åç§°'] == product_name]
        yesterday_product = yesterday_combined[yesterday_combined['äº§å“åç§°'] == product_name]

        if today_product.empty or yesterday_product.empty:
            return None

        # è®¡ç®—æ”¶ç›Šç‡
        today_asset = today_product['çœŸå®æ€»èµ„äº§'].iloc[0]
        yesterday_asset = yesterday_product['çœŸå®æ€»èµ„äº§'].iloc[0]

        return (today_asset / yesterday_asset - 1) * 100

    except Exception as e:
        return None


def get_latest_asset_data_by_folder(base_path, date_folder):
    """è·å–æŒ‡å®šæ—¥æœŸæ–‡ä»¶å¤¹ä¸­æœ€æ–°çš„èµ„äº§æ•°æ®"""
    try:
        folder_path = os.path.join(base_path, date_folder)
        asset_files = []

        for root, dirs, files in os.walk(folder_path):
            for file in files:
                if file.startswith("å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º") and file.endswith('.xlsx'):
                    file_path = os.path.join(root, file)
                    try:
                        time_part = file.replace('å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º_', '').replace('.xlsx', '')
                        timestamp = datetime.strptime(time_part, "%Y%m%d-%H%M%S")
                        asset_files.append({'file_path': file_path, 'timestamp': timestamp})
                    except:
                        continue

        if not asset_files:
            return None

        # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(asset_files, key=lambda x: x['timestamp'])

        # è¯»å–æ•°æ®
        from components.product_returns import read_total_assets_from_holding_file
        return read_total_assets_from_holding_file(latest_file['file_path'])

    except:
        return None


def get_latest_futures_data_by_date(target_date):
    """è·å–æŒ‡å®šæ—¥æœŸçš„æœ€æ–°æœŸè´§æ•°æ®"""
    try:
        futures_dir = r"C:\shared_data\æœŸè´§"

        if not os.path.exists(futures_dir):
            return None

        # è§£ææ‰€æœ‰æœŸè´§æ–‡ä»¶
        all_futures_files = []

        for file in os.listdir(futures_dir):
            if file.startswith("æœŸè´§èµ„äº§å¯¼å‡º_") and file.endswith('.xls'):
                try:
                    # è§£ææ–‡ä»¶åä¸­çš„æ—¥æœŸå’Œæ—¶é—´
                    time_part = file.replace('æœŸè´§èµ„äº§å¯¼å‡º_', '').replace('.xls', '')
                    timestamp = datetime.strptime(time_part, '%Y%m%d-%H%M%S')
                    file_date = timestamp.strftime('%Y%m%d')

                    all_futures_files.append({
                        'file_path': os.path.join(futures_dir, file),
                        'timestamp': timestamp,
                        'file_date': file_date,
                        'filename': file
                    })
                except:
                    continue

        if not all_futures_files:
            return None

        if target_date == max([f['file_date'] for f in all_futures_files]):
            # å¦‚æœæ˜¯æœ€æ–°æ—¥æœŸï¼Œé€‰æ‹©æ‰€æœ‰æ–‡ä»¶ä¸­æ—¶é—´æœ€æ–°çš„
            latest_file = max(all_futures_files, key=lambda x: x['timestamp'])
        else:
            # å¦‚æœæ˜¯å†å²æ—¥æœŸï¼Œé€‰æ‹©è¯¥æ—¥æœŸæœ€æ™šçš„æ–‡ä»¶
            target_date_files = [f for f in all_futures_files if f['file_date'] == target_date]

            if not target_date_files:
                return None

            latest_file = max(target_date_files, key=lambda x: x['timestamp'])

        # è¯»å–æ•°æ®
        from components.product_returns import read_futures_assets_from_file
        return read_futures_assets_from_file(latest_file['file_path'])

    except Exception as e:
        return None