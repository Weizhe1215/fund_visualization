"""
å®æ—¶æŒä»“çƒ­åŠ›å›¾ç»„ä»¶
"""
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import os
import glob
from datetime import datetime, timedelta
import time
import numpy as np
import plotly.figure_factory as ff
from components.product_returns import combine_assets_and_futures
from components.ruixing_data_reader import *
import json
from typing import Optional, Dict, Tuple

# æ•°æ®è·¯å¾„é…ç½®
DATA_PATHS = {
    "å®ç›˜": r"C:\shared_data\å®ç›˜\äº¤æ˜“æ•°æ®å®šé¢‘å¯¼å‡º",
    "ä»¿çœŸ": r"C:\shared_data\ä»¿çœŸ\äº¤æ˜“æ•°æ®å®šé¢‘å¯¼å‡º"
}


# åœ¨ä½ çš„ realtime_heatmap.py æ–‡ä»¶é¡¶éƒ¨ä¸´æ—¶æ·»åŠ è¿™æ®µä»£ç æµ‹è¯•
def test_time_slot():
    from datetime import datetime, time

    def is_trading_hours(dt):
        if dt.weekday() >= 5:  # å‘¨æœ«
            return False
        time_now = dt.time()
        return (time(9, 30) <= time_now <= time(15, 0))

    def get_time_slot():
        now = datetime.now()
        if is_trading_hours(now):
            minutes = (now.minute // 15) * 15
            time_slot = now.replace(minute=minutes, second=0, microsecond=0)
        else:
            time_slot = now.replace(minute=0, second=0, microsecond=0)
        return time_slot.strftime('%Y-%m-%d_%H:%M')

    current_time = datetime.now()
    time_slot = get_time_slot()
    cache_key = f"æµ‹è¯•äº§å“_å®ç›˜_{time_slot}"

    print(f"å½“å‰æ—¶é—´: {current_time}")
    print(f"æ—¶é—´ç‰‡: {time_slot}")
    print(f"ç¼“å­˜é”®: {cache_key}")
    print(f"æ˜¯å¦äº¤æ˜“æ—¶é—´: {is_trading_hours(current_time)}")


# åœ¨ render_realtime_heatmap å‡½æ•°å¼€å¤´è°ƒç”¨
test_time_slot()

def get_time_slot() -> str:
    """è·å–15åˆ†é’Ÿæ—¶é—´ç‰‡"""
    now = datetime.now()

    # äº¤æ˜“æ—¶é—´å†…ä½¿ç”¨15åˆ†é’Ÿç¼“å­˜
    if is_trading_hours(now):
        minutes = (now.minute // 15) * 15
        time_slot = now.replace(minute=minutes, second=0, microsecond=0)
    else:
        # éäº¤æ˜“æ—¶é—´ä½¿ç”¨å°æ—¶ç¼“å­˜
        time_slot = now.replace(minute=0, second=0, microsecond=0)

    return time_slot.strftime('%Y-%m-%d_%H:%M')


def is_trading_hours(dt: datetime) -> bool:
    """åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´"""
    if dt.weekday() >= 5:  # å‘¨æœ«
        return False

    from datetime import time
    time_now = dt.time()
    return (time(9, 30) <= time_now <= time(15, 0))


def get_cache_key(product_name: str, data_source: str, time_slot: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    return f"{product_name}_{data_source}_{time_slot}"


def get_latest_data_file_time(data_source: str) -> datetime:
    """è·å–æœ€æ–°æ•°æ®æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´"""
    try:
        file_info = get_latest_holding_files(data_source)

        if not file_info or not file_info.get('files'):
            return datetime.now()

        latest_time = datetime.min

        for product_id, file_path in file_info['files'].items():
            # ç¡®ä¿file_pathæ˜¯æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„
            if isinstance(file_path, str) and os.path.exists(file_path):
                file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                if file_time > latest_time:
                    latest_time = file_time

        return latest_time if latest_time != datetime.min else datetime.now()

    except Exception as e:
        print(f"è·å–æ–‡ä»¶æ—¶é—´å¤±è´¥: {e}")
        return datetime.now()


def should_use_cache(product_name: str, data_source: str, db) -> Tuple[bool, Optional[Dict]]:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨ç¼“å­˜"""
    try:
        time_slot = get_time_slot()
        cache_key = get_cache_key(product_name, data_source, time_slot)

        # è·å–ç¼“å­˜æ•°æ®
        cache_result = db.get_cache_data(cache_key)
        if not cache_result:
            return False, None

        # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦æ¯”ç¼“å­˜æ›´æ–°
        latest_file_time = get_latest_data_file_time(data_source)
        cache_file_time = cache_result.get('data_file_time')

        if cache_file_time and latest_file_time > cache_file_time:
            return False, None

        return True, cache_result['data']

    except Exception as e:
        return False, None


def calculate_product_data_realtime(product_name: str, data_source: str, db) -> Dict:
    """å®æ—¶è®¡ç®—äº§å“æ•°æ®"""
    try:
        # ä½¿ç”¨ç°æœ‰çš„æ–‡ä»¶è·å–é€»è¾‘
        file_info = get_latest_holding_files(data_source)

        if not file_info or not file_info.get('files'):
            return {}

        # è·å–æ•°æ®åº“ä¸­çš„äº§å“åˆ—è¡¨
        db_products = db.get_products()
        db_product_names = {p['product_name']: p['product_code'] for p in db_products}

        # è¯»å–æ¯ä¸ªäº§å“çš„æœ€æ–°æ–‡ä»¶æ•°æ®å¹¶åŒ¹é…äº§å“
        all_data = {}

        for product_id, file_path in file_info['files'].items():
            # éªŒè¯æ–‡ä»¶è·¯å¾„æ˜¯å¦æœ‰æ•ˆ
            if not os.path.exists(file_path):
                continue

            df = read_holding_file(file_path)
            if not df.empty and 'product_name' in df.columns:
                # è·å–æ–‡ä»¶ä¸­çš„äº§å“åç§°
                file_product_names = df['product_name'].unique()

                for prod_name in file_product_names:
                    # å°è¯•åŒ¹é…æ•°æ®åº“ä¸­çš„äº§å“
                    if prod_name in db_product_names:
                        product_data = df[df['product_name'] == prod_name].copy()
                        if not product_data.empty:
                            # å¦‚æœäº§å“å·²å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
                            if prod_name in all_data:
                                # åˆå¹¶æŒä»“æ•°æ®ï¼ŒæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„ï¼Œå¸‚å€¼ç›¸åŠ ï¼Œæ¶¨è·Œå¹…å–å¹³å‡
                                existing_data = all_data[prod_name]
                                combined_data = pd.concat([existing_data, product_data], ignore_index=True)

                                # æŒ‰è‚¡ç¥¨ä»£ç åˆå¹¶
                                merged_data = combined_data.groupby('stock_code').agg({
                                    'stock_name': 'first',  # å–ç¬¬ä¸€ä¸ªåç§°
                                    'market_value': 'sum',  # å¸‚å€¼ç›¸åŠ 
                                    'change_pct': 'mean',  # æ¶¨è·Œå¹…å–å¹³å‡
                                    'product_name': 'first'
                                }).reset_index()

                                all_data[prod_name] = merged_data
                            else:
                                all_data[prod_name] = product_data

        if product_name not in all_data:
            return {}

        product_data = all_data[product_name]

        # è®¡ç®—æƒé‡ï¼ˆåŸºäºå¸‚å€¼ï¼‰
        if 'weight' not in product_data.columns:
            product_data['weight'] = product_data['market_value'] / product_data['market_value'].sum() * 100

        # è®¡ç®—æ”¶ç›Šç‡
        return_rate = get_product_return_from_holdings(product_name, data_source, db)

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        positive_count = len(product_data[product_data['change_pct'] > 0])
        total_count = len(product_data)
        total_value = product_data['market_value'].sum()

        # è®¡ç®—å‰5åæ•°æ®
        top_gainers = []
        top_losers = []

        if not product_data.empty:
            gainers_data = product_data[product_data['change_pct'] > 0]
            if not gainers_data.empty:
                top_gainers_df = gainers_data.nlargest(5, 'change_pct')[['stock_name', 'change_pct', 'weight']]
                top_gainers = top_gainers_df.to_dict('records')

            losers_data = product_data[product_data['change_pct'] < 0]
            if not losers_data.empty:
                top_losers_df = losers_data.nsmallest(5, 'change_pct')[['stock_name', 'change_pct', 'weight']]
                top_losers = top_losers_df.to_dict('records')

        return {
            'return_rate': return_rate,
            'positive_count': positive_count,
            'total_count': total_count,
            'total_value': total_value,
            'product_data': product_data.to_dict('records'),
            'top_gainers': top_gainers,
            'top_losers': top_losers,
            'calculation_timestamp': datetime.now().isoformat()
        }

    except Exception as e:
        print(f"è®¡ç®—äº§å“æ•°æ®å¤±è´¥: {e}")
        return {}


def get_product_data_with_cache(product_name: str, data_source: str, db) -> Dict:
    """è·å–äº§å“æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç¼“å­˜
    use_cache, cached_data = should_use_cache(product_name, data_source, db)

    if use_cache and cached_data:
        return cached_data

    # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®æ—¶è®¡ç®—
    result = calculate_product_data_realtime(product_name, data_source, db)

    # ä¿å­˜åˆ°ç¼“å­˜
    if result:
        time_slot = get_time_slot()
        cache_key = get_cache_key(product_name, data_source, time_slot)
        data_file_time = get_latest_data_file_time(data_source)

        db.save_cache_data(cache_key, product_name, data_source, time_slot, result, data_file_time)

    return result

def create_heatmap_data(df, mode='price_change'):
    """åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®"""
    if df.empty:
        return None, None, None, None

    # è®¡ç®—æƒé‡ï¼ˆåŸºäºå¸‚å€¼ï¼‰
    df['weight'] = df['market_value'] / df['market_value'].sum() * 100

    # åˆ†ä¸ºæ¶¨è·Œä¸¤ç»„
    rising_df = df[df['change_pct'] > 0].copy()
    falling_df = df[df['change_pct'] < 0].copy()

    if mode == 'price_change':
        # æ¨¡å¼1ï¼šçº¯æ¶¨è·Œå¹…ï¼Œé¢ç§¯å®Œå…¨åŸºäºæ¶¨è·Œå¹…å¤§å°
        if not rising_df.empty:
            # é¢ç§¯ = æ¶¨è·Œå¹…çš„å¹³æ–¹ï¼ˆæ”¾å¤§å·®å¼‚ï¼‰
            rising_df['size'] = rising_df['change_pct'] ** 2
            rising_df['color_value'] = rising_df['change_pct']

        if not falling_df.empty:
            # é¢ç§¯ = è·Œå¹…çš„å¹³æ–¹
            falling_df['size'] = falling_df['change_pct'] ** 2  # è´Ÿæ•°çš„å¹³æ–¹è¿˜æ˜¯æ­£æ•°
            falling_df['color_value'] = falling_df['change_pct']

        title_rising = "ä¸Šæ¶¨è‚¡ç¥¨çƒ­åŠ›å›¾ï¼ˆé¢ç§¯=æ¶¨å¹…ï¼‰"
        title_falling = "ä¸‹è·Œè‚¡ç¥¨çƒ­åŠ›å›¾ï¼ˆé¢ç§¯=è·Œå¹…ï¼‰"
        color_title = "æ¶¨è·Œå¹… (%)"
    else:
        # æ¨¡å¼2ï¼šæ”¶ç›Šè´¡çŒ®ï¼Œé¢ç§¯åŸºäºè´¡çŒ®åº¦
        # å…ˆè®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„åŸå§‹è´¡çŒ®åº¦
        df['raw_contribution'] = df['change_pct'] * df['weight'] / 100
        total_abs_contribution = df['raw_contribution'].abs().sum()

        # å½’ä¸€åŒ–è´¡çŒ®åº¦
        if total_abs_contribution > 0:
            df['contribution'] = (df['raw_contribution'].abs() / total_abs_contribution) * 100
            df['contribution_signed'] = df['raw_contribution'] / total_abs_contribution * 100  # ä¿ç•™æ­£è´Ÿå·ç”¨äºé¢œè‰²
        else:
            df['contribution'] = 0
            df['contribution_signed'] = 0

        # é‡æ–°åˆ†ç»„
        rising_df = df[df['change_pct'] > 0].copy() if not df[df['change_pct'] > 0].empty else pd.DataFrame()
        falling_df = df[df['change_pct'] < 0].copy() if not df[df['change_pct'] < 0].empty else pd.DataFrame()

        if not rising_df.empty:
            rising_df['size'] = rising_df['contribution']  # é¢ç§¯ = å½’ä¸€åŒ–è´¡çŒ®åº¦
            rising_df['color_value'] = rising_df['contribution_signed']  # é¢œè‰² = å¸¦ç¬¦å·çš„è´¡çŒ®åº¦

        if not falling_df.empty:
            falling_df['size'] = falling_df['contribution']  # é¢ç§¯ = å½’ä¸€åŒ–è´¡çŒ®åº¦
            falling_df['color_value'] = falling_df['contribution_signed']  # é¢œè‰² = å¸¦ç¬¦å·çš„è´¡çŒ®åº¦

        title_rising = "æ­£è´¡çŒ®è‚¡ç¥¨çƒ­åŠ›å›¾ï¼ˆé¢ç§¯=è´¡çŒ®åº¦ï¼‰"
        title_falling = "è´Ÿè´¡çŒ®è‚¡ç¥¨çƒ­åŠ›å›¾ï¼ˆé¢ç§¯=è´¡çŒ®åº¦ï¼‰"
        color_title = "è´¡çŒ®åº¦ (%)"

    return rising_df, falling_df, (title_rising, title_falling), color_title


def render_dual_treemap_heatmap(rising_df, falling_df, titles, color_title, mode='price_change'):
    """æ¸²æŸ“åŒçƒ­åŠ›å›¾ï¼ˆæ¶¨è·Œåˆ†å¼€ï¼‰"""
    title_rising, title_falling = titles

    col1, col2 = st.columns(2)

    with col1:
        st.subheader(title_rising)
        if rising_df is not None and not rising_df.empty:
            render_single_treemap(rising_df, color_title, 'Reds', mode)
        else:
            st.info("æš‚æ— ä¸Šæ¶¨è‚¡ç¥¨")

    with col2:
        st.subheader(title_falling)
        if falling_df is not None and not falling_df.empty:
            render_single_treemap(falling_df, color_title, 'Greens_r', mode)
        else:
            st.info("æš‚æ— ä¸‹è·Œè‚¡ç¥¨")


def render_single_treemap(df, color_title, colorscale, mode='price_change'):
    """æ¸²æŸ“å•ä¸ªçƒ­åŠ›å›¾"""
    # æ ¹æ®æ¨¡å¼å‡†å¤‡ä¸åŒçš„æ˜¾ç¤ºæ ‡ç­¾
    if 'contribution' in df.columns:  # è´¡çŒ®åº¦æ¨¡å¼
        df['label'] = df.apply(lambda x: f"{x['stock_name']}<br>{x['stock_code']}<br>{x['contribution']:.3f}%", axis=1)
    else:  # ä»·æ ¼æ¶¨è·Œæ¨¡å¼
        df['label'] = df.apply(lambda x: f"{x['stock_name']}<br>{x['stock_code']}<br>{x['change_pct']:.2f}%", axis=1)

    # ä¸ºä¸Šæ¶¨å’Œä¸‹è·Œä½¿ç”¨ä¸åŒçš„é«˜çº§é…è‰²
    if colorscale == 'Reds':
        colorscale = 'Reds'  # ä¿æŒçº¢è‰²ç³»
    elif colorscale == 'Greens_r':
        colorscale = 'Greens_r'  # æ”¹ä¸ºæ­£å‘ç»¿è‰²ç³»

    fig = go.Figure(go.Treemap(
        labels=df['label'],
        values=df['size'],
        parents=[""] * len(df),
        marker=dict(
            colorscale=colorscale,
            colorbar=dict(title=color_title),
            colors=df['color_value'],
            line=dict(width=2, color='rgba(255,255,255,0.3)')  # æ·»åŠ è¾¹æ¡†çº¿
        ),
        textinfo="label",
        textfont_size=11,
        hovertemplate='<b>%{label}</b><br>' +
                      f'{color_title}: %{{color:.2f}}<br>' +
                      'é¢ç§¯æƒé‡: %{value:.2f}<br>' +
                      '<extra></extra>'
    ))

    fig.update_layout(
        height=400,
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        margin=dict(t=20, b=20, l=20, r=20)
    )

    st.plotly_chart(fig, use_container_width=True)


def get_latest_holding_files(data_source="å®ç›˜"):
    """è·å–æ¯ä¸ªäº§å“æœ€æ–°çš„æŒä»“æ–‡ä»¶"""
    try:
        base_path = DATA_PATHS[data_source]
        if not os.path.exists(base_path):
            return {}

        # è·å–æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹å¹¶æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
        date_folders = [f for f in os.listdir(base_path)
                        if f.isdigit() and len(f) == 8 and os.path.isdir(os.path.join(base_path, f))]

        if not date_folders:
            return {}

        latest_date_folder = max(date_folders)
        date_folder_path = os.path.join(base_path, latest_date_folder)

        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰æŒä»“æ–‡ä»¶
        all_files = []
        for root, dirs, files in os.walk(date_folder_path):
            for file in files:
                # æ ¹æ®æ•°æ®æºä½¿ç”¨ä¸åŒçš„åŒ¹é…è§„åˆ™
                if data_source == "ä»¿çœŸ":
                    # ä»¿çœŸæ”¯æŒä¸‰ç§æ ¼å¼
                    if ((file.startswith("å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º") or
                         file.startswith("å•å…ƒè´¦æˆ·å±‚èµ„äº§èµ„äº§å¯¼å‡º") or
                         file.startswith("å•å…ƒè´¦æˆ·å±‚èµ„äº§æŒä»“å¯¼å‡º")) and
                            (file.endswith('.xlsx') or file.endswith('.csv'))):
                        all_files.append(os.path.join(root, file))
                else:
                    # å®ç›˜ä¿æŒåŸæ ¼å¼
                    if file.startswith("å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º") and (file.endswith('.xlsx') or file.endswith('.csv')):
                        all_files.append(os.path.join(root, file))

        # æŒ‰äº§å“åˆ†ç»„æ–‡ä»¶
        product_files = {}
        for file_path in all_files:
            filename = os.path.basename(file_path)
            # è§£ææ–‡ä»¶åï¼šå•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º_ä¸œè´¢EMC_æ™®é€š_20250625-123500
            # æˆ–ï¼šå•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º_å¼€æºATX_æ™®é€š1_20250625-121200

            # æ ¹æ®æ–‡ä»¶åå‰ç¼€ç§»é™¤å¯¹åº”çš„å‰ç¼€
            if filename.startswith("å•å…ƒè´¦æˆ·å±‚èµ„äº§æŒä»“å¯¼å‡º"):
                # æ–°æŒä»“æ ¼å¼: å•å…ƒè´¦æˆ·å±‚èµ„äº§æŒä»“å¯¼å‡º_èµ„äº§è´¦æˆ·1_YYYYMMDD-HHMMSS.xlsx
                name_part = filename.replace('å•å…ƒè´¦æˆ·å±‚èµ„äº§æŒä»“å¯¼å‡º_', '')
            elif filename.startswith("å•å…ƒè´¦æˆ·å±‚èµ„äº§èµ„äº§å¯¼å‡º"):
                # æ–°æ€»èµ„äº§æ ¼å¼: å•å…ƒè´¦æˆ·å±‚èµ„äº§èµ„äº§å¯¼å‡º_YYYYMMDD-HHMMSS.xlsx
                name_part = filename.replace('å•å…ƒè´¦æˆ·å±‚èµ„äº§èµ„äº§å¯¼å‡º_', '')
            else:
                # åŸæ ¼å¼
                name_part = filename.replace('å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º_', '').replace('å•å…ƒèµ„äº§è´¦æˆ·æŒä»“å¯¼å‡º-', '')

            # åˆ†å‰²è·å–äº§å“æ ‡è¯†å’Œæ—¶é—´
            parts = name_part.split('_')

            if len(parts) >= 2:
                # æœ€åä¸€éƒ¨åˆ†åŒ…å«æ—¥æœŸæ—¶é—´
                datetime_part = parts[-1]
                # äº§å“æ ‡è¯†æ˜¯é™¤äº†æœ€åä¸€éƒ¨åˆ†çš„å…¶ä»–éƒ¨åˆ†
                product_identifier = '_'.join(parts[:-1])

                # æå–æ—¶é—´æˆ³
                if '-' in datetime_part:
                    date_time = datetime_part.replace('.xlsx', '').replace('.csv', '')
                    try:
                        timestamp = datetime.strptime(date_time, "%Y%m%d-%H%M%S")
                    except:
                        continue
                else:
                    continue

                if product_identifier not in product_files:
                    product_files[product_identifier] = []

                product_files[product_identifier].append({
                    'file_path': file_path,
                    'timestamp': timestamp,
                    'filename': filename
                })

        # è·å–æ¯ä¸ªäº§å“æœ€æ–°çš„æ–‡ä»¶
        latest_files = {}
        for product_id, files_list in product_files.items():
            if files_list:
                latest_file = max(files_list, key=lambda x: x['timestamp'])
                latest_files[product_id] = latest_file['file_path']

        return {
            'latest_date': latest_date_folder,
            'files': latest_files,
            'file_count': sum(len(files) for files in product_files.values()),
            'data_source': data_source  # æ·»åŠ æ•°æ®æºä¿¡æ¯
        }

    except Exception as e:
        st.error(f"è¯»å–{data_source}æ–‡ä»¶å¤¹å¤±è´¥: {e}")
        return {}


def read_holding_file(file_path):
    """è¯»å–å•ä¸ªæŒä»“æ–‡ä»¶"""
    try:
        if file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        else:
            df = pd.read_csv(file_path, encoding='utf-8-sig')

        # æ ‡å‡†åŒ–åˆ—åï¼Œé¿å…é‡å¤
        column_mapping = {}
        used_standard_names = set()

        for col in df.columns:
            if 'äº§å“åç§°' in col and 'product_name' not in used_standard_names:
                column_mapping[col] = 'product_name'
                used_standard_names.add('product_name')
            elif 'è¯åˆ¸ä»£ç ' in col and 'stock_code' not in used_standard_names:
                column_mapping[col] = 'stock_code'
                used_standard_names.add('stock_code')
            elif 'è¯åˆ¸åç§°' in col and 'stock_name' not in used_standard_names:
                column_mapping[col] = 'stock_name'
                used_standard_names.add('stock_name')
            elif 'æŒä»“å¸‚å€¼' in col and 'market_value' not in used_standard_names:
                column_mapping[col] = 'market_value'
                used_standard_names.add('market_value')
            elif ('æ¶¨è·Œå¹…' in col or 'å½“æ—¥æ¶¨è·Œå¹…' in col) and 'change_pct' not in used_standard_names:
                column_mapping[col] = 'change_pct'
                used_standard_names.add('change_pct')
            elif 'æ—¥æœŸ' in col and 'date' not in used_standard_names:
                column_mapping[col] = 'date'
                used_standard_names.add('date')

        # åº”ç”¨åˆ—åæ˜ å°„
        df = df.rename(columns=column_mapping)

        # æ£€æŸ¥å¿…éœ€åˆ—
        required_cols = ['product_name', 'stock_code', 'stock_name', 'market_value', 'change_pct']
        missing_cols = [col for col in required_cols if col not in df.columns]

        if missing_cols:
            st.warning(f"æ–‡ä»¶ {os.path.basename(file_path)} ç¼ºå°‘åˆ—: {missing_cols}")
            st.write(f"å®é™…åˆ—å: {list(df.columns)}")
            return pd.DataFrame()

        # æ•°æ®ç±»å‹è½¬æ¢
        df['stock_code'] = df['stock_code'].astype(str).str.zfill(6)
        df['market_value'] = pd.to_numeric(df['market_value'], errors='coerce')
        df['change_pct'] = pd.to_numeric(df['change_pct'], errors='coerce')

        # åˆ é™¤æ— æ•ˆæ•°æ®
        df = df.dropna(subset=['market_value', 'change_pct'])
        df = df[df['market_value'] > 0]

        return df

    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return pd.DataFrame()


def render_realtime_heatmap(db):
    """æ¸²æŸ“å®æ—¶æŒä»“çƒ­åŠ›å›¾é¡µé¢"""
    st.header("ğŸ“Š å®æ—¶æŒä»“çƒ­åŠ›å›¾")

    # æ·»åŠ æ•°æ®æºé€‰æ‹©
    col1, col2 = st.columns([1, 3])
    with col1:
        data_source = st.selectbox(
            "æ•°æ®æº",
            options=["å®ç›˜", "ä»¿çœŸ"],
            key="data_source_selector"
        )

    with col2:
        st.info(f"æ•°æ®è·¯å¾„: {DATA_PATHS[data_source]}")

    # æ·»åŠ åˆ·æ–°æŒ‰é’®å’Œè‡ªåŠ¨åˆ·æ–°
    col1, col2, col3 = st.columns([1, 1, 2])

    with col1:
        if st.button("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°", type="primary"):
            st.rerun()

    with col2:
        auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–° (5åˆ†é’Ÿ)", value=False)

    with col3:
        last_update = st.empty()

    # è·å–æœ€æ–°æ–‡ä»¶
    file_info = get_latest_holding_files(data_source)

    if not file_info or not file_info.get('files'):
        st.error(f"æœªæ‰¾åˆ°{data_source}æŒä»“æ–‡ä»¶")
        return

    st.success(
        f"æœ€æ–°æ—¥æœŸ: {file_info['latest_date']}, æ€»æ–‡ä»¶æ•°: {file_info.get('file_count', 0)}, äº§å“æ•°: {len(file_info['files'])}")

    # è·å–æ•°æ®åº“ä¸­çš„äº§å“åˆ—è¡¨
    db_products = db.get_products()
    db_product_names = {p['product_name']: p['product_code'] for p in db_products}

    # è¯»å–æ¯ä¸ªäº§å“çš„æœ€æ–°æ–‡ä»¶æ•°æ®å¹¶åŒ¹é…äº§å“
    all_data = {}
    matched_products = []

    for product_id, file_path in file_info['files'].items():
        df = read_holding_file(file_path)
        if not df.empty and 'product_name' in df.columns:
            # è·å–æ–‡ä»¶ä¸­çš„äº§å“åç§°
            file_product_names = df['product_name'].unique()

            for prod_name in file_product_names:
                # å°è¯•åŒ¹é…æ•°æ®åº“ä¸­çš„äº§å“
                if prod_name in db_product_names:
                    product_data = df[df['product_name'] == prod_name].copy()
                    if not product_data.empty:
                        # å¦‚æœäº§å“å·²å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
                        if prod_name in all_data:
                            # åˆå¹¶æŒä»“æ•°æ®ï¼ŒæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„ï¼Œå¸‚å€¼ç›¸åŠ ï¼Œæ¶¨è·Œå¹…å–å¹³å‡
                            existing_data = all_data[prod_name]
                            combined_data = pd.concat([existing_data, product_data], ignore_index=True)

                            # æŒ‰è‚¡ç¥¨ä»£ç åˆå¹¶
                            merged_data = combined_data.groupby('stock_code').agg({
                                'stock_name': 'first',  # å–ç¬¬ä¸€ä¸ªåç§°
                                'market_value': 'sum',  # å¸‚å€¼ç›¸åŠ 
                                'change_pct': 'mean',  # æ¶¨è·Œå¹…å–å¹³å‡
                                'product_name': 'first'
                            }).reset_index()

                            all_data[prod_name] = merged_data
                        else:
                            all_data[prod_name] = product_data
                            matched_products.append(prod_name)

    if not matched_products:
        st.warning(f"æœªæ‰¾åˆ°ä¸æ•°æ®åº“åŒ¹é…çš„{data_source}äº§å“æ•°æ®")
        st.info("è¯·ç¡®ä¿æ–‡ä»¶ä¸­çš„äº§å“åç§°ä¸æ•°æ®åº“ä¸­çš„äº§å“åç§°ä¸€è‡´")
        return

    # âœ… æ–°å¢ï¼šåˆ›å»ºä¸»è¦å†…å®¹åŒºåŸŸå’Œä¾§è¾¹æ 
    col_main, col_sidebar = st.columns([2.5, 1])

    # âœ… æ–°å¢ï¼šåœ¨ä¾§è¾¹æ æ˜¾ç¤ºäº§å“æ”¶ç›Šè¡¨ç°ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    with col_sidebar:
        st.subheader("ğŸ“ˆ å½“æ—¥äº§å“è¡¨ç°")

        # è®¡ç®—æ¯ä¸ªäº§å“çš„æ”¶ç›Šç‡ - ä½¿ç”¨ç¼“å­˜
        product_returns = []
        for product_name in matched_products:
            # âœ… ä½¿ç”¨ç¼“å­˜è·å–æ”¶ç›Šç‡
            cached_result = get_product_data_with_cache(product_name, data_source, db)
            if cached_result and 'return_rate' in cached_result:
                return_rate = cached_result['return_rate']
                if return_rate is not None:
                    product_returns.append({
                        'product_name': product_name,
                        'return_rate': return_rate
                    })

        if product_returns:
            # åˆ›å»ºæ”¶ç›Šç‡æŸ±çŠ¶å›¾
            returns_df = pd.DataFrame(product_returns)
            returns_df = returns_df.sort_values('return_rate', ascending=True)

            # ä½¿ç”¨plotlyåˆ›å»ºæŸ±çŠ¶å›¾
            import plotly.graph_objects as go

            colors = ['#90EE90' if x < 0 else 'pink' for x in returns_df['return_rate']]

            fig = go.Figure(data=[
                go.Bar(
                    y=returns_df['product_name'],
                    x=returns_df['return_rate'],
                    orientation='h',
                    marker=dict(color=colors),
                    text=[f"{x:.2f}%" for x in returns_df['return_rate']],
                    textposition='outside',
                    hovertemplate='<b>%{y}</b><br>æ”¶ç›Šç‡: %{x:.2f}%<extra></extra>'
                )
            ])

            fig.update_layout(
                title="äº§å“æ”¶ç›Šç‡æ’è¡Œ",
                xaxis_title="æ”¶ç›Šç‡ (%)",
                yaxis_title="äº§å“åç§°",
                height=300,
                margin=dict(l=10, r=10, t=50, b=10),
                font=dict(size=10)
            )

            st.plotly_chart(fig, use_container_width=True)

            # æ˜¾ç¤ºå…·ä½“æ•°å€¼è¡¨æ ¼
            st.write("**è¯¦ç»†æ•°æ®ï¼š**")
            display_df = returns_df.copy()
            display_df['return_rate'] = display_df['return_rate'].apply(lambda x: f"{x:.2f}%")
            display_df.columns = ['äº§å“åç§°', 'å½“æ—¥æ”¶ç›Šç‡']
            st.dataframe(display_df, use_container_width=True, hide_index=True)

        else:
            st.info("æš‚æ— æ”¶ç›Šç‡æ•°æ®")

    # ä¸»è¦å†…å®¹åŒºåŸŸï¼šåŸæœ‰çš„äº§å“é€‰æ‹©å’Œçƒ­åŠ›å›¾
    with col_main:
        # äº§å“é€‰æ‹©ä¸‹æ‹‰æ¡†
        selected_product_name = st.selectbox(
            f"é€‰æ‹©è¦åˆ†æçš„{data_source}äº§å“",
            options=matched_products,
            key=f"realtime_product_selector_{data_source}"
        )

        if selected_product_name:
            # âœ… ä½¿ç”¨ç¼“å­˜è·å–äº§å“æ•°æ®
            cached_result = get_product_data_with_cache(selected_product_name, data_source, db)

            if cached_result and 'product_data' in cached_result:
                # ä»ç¼“å­˜æ¢å¤DataFrame
                product_data = pd.DataFrame(cached_result['product_data'])

                # æ˜¾ç¤ºæ•°æ®æ¦‚å†µ
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("æŒä»“è‚¡ç¥¨æ•°", cached_result.get('total_count', 0))

                with col2:
                    total_value = cached_result.get('total_value', 0)
                    st.metric("æ€»å¸‚å€¼", f"{total_value:,.0f}")

                with col3:
                    return_rate = cached_result.get('return_rate')
                    if return_rate is not None:
                        st.metric("å½“æ—¥æ”¶ç›Šç‡(å·²è°ƒæ•´)", f"{return_rate:.2f}%")
                    else:
                        st.metric("å½“æ—¥æ”¶ç›Šç‡", "è®¡ç®—å¤±è´¥")

                with col4:
                    positive_count = cached_result.get('positive_count', 0)
                    total_count = cached_result.get('total_count', 0)
                    st.metric("ä¸Šæ¶¨è‚¡ç¥¨æ•°", f"{positive_count}/{total_count}")

                # çƒ­åŠ›å›¾å±•ç¤º
                st.divider()
                st.subheader("æŒä»“çƒ­åŠ›å›¾")

                # æ¨¡å¼åˆ‡æ¢
                col1, col2 = st.columns(2)
                with col1:
                    heatmap_mode = st.radio(
                        "çƒ­åŠ›å›¾æ¨¡å¼",
                        options=['price_change', 'contribution'],
                        format_func=lambda x: "ä»·æ ¼æ¶¨è·Œ" if x == 'price_change' else "æ”¶ç›Šè´¡çŒ®",
                        key=f"heatmap_mode_{data_source}"
                    )

                # ç”Ÿæˆçƒ­åŠ›å›¾æ•°æ®
                rising_df, falling_df, titles, color_title = create_heatmap_data(product_data, heatmap_mode)

                # æ¸²æŸ“çƒ­åŠ›å›¾
                if rising_df is not None or falling_df is not None:
                    render_dual_treemap_heatmap(rising_df, falling_df, titles, color_title, heatmap_mode)

                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    st.subheader("è¯¦ç»†ç»Ÿè®¡")

                    col1, col2 = st.columns(2)

                    with col1:
                        st.write("**æ¶¨å¹…å‰5å:**")
                        # ä½¿ç”¨ç¼“å­˜çš„top_gainersæ•°æ®
                        top_gainers = cached_result.get('top_gainers', [])
                        if top_gainers:
                            gainers_df = pd.DataFrame(top_gainers)
                            if 'change_pct' in gainers_df.columns and 'weight' in gainers_df.columns:
                                gainers_df['change_pct'] = gainers_df['change_pct'].apply(lambda x: f"{x:.2f}%")
                                gainers_df['weight'] = gainers_df['weight'].apply(lambda x: f"{x:.2f}%")
                                gainers_df.columns = ['è‚¡ç¥¨åç§°', 'æ¶¨è·Œå¹…', 'æƒé‡']
                                st.dataframe(gainers_df, use_container_width=True, hide_index=True)
                        else:
                            st.info("æš‚æ— ä¸Šæ¶¨è‚¡ç¥¨")

                    with col2:
                        st.write("**è·Œå¹…å‰5å:**")
                        # ä½¿ç”¨ç¼“å­˜çš„top_losersæ•°æ®
                        top_losers = cached_result.get('top_losers', [])
                        if top_losers:
                            losers_df = pd.DataFrame(top_losers)
                            if 'change_pct' in losers_df.columns and 'weight' in losers_df.columns:
                                losers_df['change_pct'] = losers_df['change_pct'].apply(lambda x: f"{x:.2f}%")
                                losers_df['weight'] = losers_df['weight'].apply(lambda x: f"{x:.2f}%")
                                losers_df.columns = ['è‚¡ç¥¨åç§°', 'æ¶¨è·Œå¹…', 'æƒé‡']
                                st.dataframe(losers_df, use_container_width=True, hide_index=True)
                        else:
                            st.info("æš‚æ— ä¸‹è·Œè‚¡ç¥¨")

                # æ˜¾ç¤ºæ•°æ®è®¡ç®—æ—¶é—´
                calc_time = cached_result.get('calculation_timestamp')
                if calc_time:
                    calc_dt = datetime.fromisoformat(calc_time)
                    st.caption(f"æ•°æ®è®¡ç®—æ—¶é—´: {calc_dt.strftime('%Y-%m-%d %H:%M:%S')}")

            elif selected_product_name in all_data:
                # å›é€€åˆ°åŸå§‹é€»è¾‘ï¼ˆç¼“å­˜å¤±è´¥æ—¶ï¼‰
                product_data = all_data[selected_product_name]

                # æ˜¾ç¤ºæ•°æ®æ¦‚å†µ
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("æŒä»“è‚¡ç¥¨æ•°", len(product_data))

                with col2:
                    total_value = product_data['market_value'].sum()
                    st.metric("æ€»å¸‚å€¼", f"{total_value:,.0f}")

                with col3:
                    # âœ… ä¼ å…¥dbå‚æ•°ï¼Œå¯ç”¨å‡ºå…¥é‡‘è°ƒæ•´
                    actual_return = get_product_return_from_holdings(selected_product_name, data_source, db)
                    if actual_return is not None:
                        st.metric("å½“æ—¥æ”¶ç›Šç‡(å·²è°ƒæ•´)", f"{actual_return:.2f}%")
                    else:
                        st.metric("å½“æ—¥æ”¶ç›Šç‡", "è®¡ç®—å¤±è´¥")

                with col4:
                    positive_count = len(product_data[product_data['change_pct'] > 0])
                    st.metric("ä¸Šæ¶¨è‚¡ç¥¨æ•°", f"{positive_count}/{len(product_data)}")

                # çƒ­åŠ›å›¾å±•ç¤º
                st.divider()
                st.subheader("æŒä»“çƒ­åŠ›å›¾")

                # æ¨¡å¼åˆ‡æ¢
                col1, col2 = st.columns(2)
                with col1:
                    heatmap_mode = st.radio(
                        "çƒ­åŠ›å›¾æ¨¡å¼",
                        options=['price_change', 'contribution'],
                        format_func=lambda x: "ä»·æ ¼æ¶¨è·Œ" if x == 'price_change' else "æ”¶ç›Šè´¡çŒ®",
                        key=f"heatmap_mode_{data_source}"
                    )

                # ç”Ÿæˆçƒ­åŠ›å›¾æ•°æ®
                rising_df, falling_df, titles, color_title = create_heatmap_data(product_data, heatmap_mode)

                # æ¸²æŸ“çƒ­åŠ›å›¾
                if rising_df is not None or falling_df is not None:
                    render_dual_treemap_heatmap(rising_df, falling_df, titles, color_title, heatmap_mode)

                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    st.subheader("è¯¦ç»†ç»Ÿè®¡")

                    col1, col2 = st.columns(2)

                    with col1:
                        st.write("**æ¶¨å¹…å‰5å:**")
                        if rising_df is not None and not rising_df.empty:
                            top_gainers = rising_df.nlargest(5, 'change_pct')[['stock_name', 'change_pct', 'weight']]
                            top_gainers['change_pct'] = top_gainers['change_pct'].apply(lambda x: f"{x:.2f}%")
                            top_gainers['weight'] = top_gainers['weight'].apply(lambda x: f"{x:.2f}%")
                            top_gainers.columns = ['è‚¡ç¥¨åç§°', 'æ¶¨è·Œå¹…', 'æƒé‡']
                            st.dataframe(top_gainers, use_container_width=True, hide_index=True)
                        else:
                            st.info("æš‚æ— ä¸Šæ¶¨è‚¡ç¥¨")

                    with col2:
                        st.write("**è·Œå¹…å‰5å:**")
                        if falling_df is not None and not falling_df.empty:
                            top_losers = falling_df.nsmallest(5, 'change_pct')[['stock_name', 'change_pct', 'weight']]
                            top_losers['change_pct'] = top_losers['change_pct'].apply(lambda x: f"{x:.2f}%")
                            top_losers['weight'] = top_losers['weight'].apply(lambda x: f"{x:.2f}%")
                            top_losers.columns = ['è‚¡ç¥¨åç§°', 'æ¶¨è·Œå¹…', 'æƒé‡']
                            st.dataframe(top_losers, use_container_width=True, hide_index=True)
                        else:
                            st.info("æš‚æ— ä¸‹è·Œè‚¡ç¥¨")

    # è‡ªåŠ¨åˆ·æ–°é€»è¾‘
    if auto_refresh:
        time.sleep(300)  # 5åˆ†é’Ÿ
        st.rerun()

    last_update.write(f"æœ€åæ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # åªæœ‰åœ¨é€‰æ‹©äº†äº§å“ä¹‹åæ‰æ˜¾ç¤ºå‡ºå…¥é‡‘ç®¡ç†
    if 'selected_product_name' in locals() and selected_product_name and selected_product_name in all_data:

        st.divider()
        st.subheader("ğŸ’° å‡ºå…¥é‡‘ç®¡ç†")

        col_input, col_history = st.columns([1, 1])

        # å·¦åˆ—ï¼šå½•å…¥å‡ºå…¥é‡‘
        with col_input:
            st.write("**å½•å…¥ä»Šæ—¥å‡ºå…¥é‡‘**")

            cash_amount = st.number_input(
                "é‡‘é¢ï¼ˆä¸‡å…ƒï¼‰",
                value=0.0,
                step=1.0,
                min_value=0.0,
                key="cash_flow_amount"
            )

            flow_type = st.selectbox(
                "ç±»å‹",
                ["å‡ºé‡‘", "å…¥é‡‘"],
                key="cash_flow_type"
            )

            note = st.text_input(
                "å¤‡æ³¨",
                placeholder="å¯é€‰ï¼Œå¦‚ï¼šå®¢æˆ·èµå›ã€è¿½åŠ æŠ•èµ„ç­‰",
                key="cash_flow_note"
            )

            col_btn1, col_btn2 = st.columns(2)

            with col_btn1:
                if st.button("âœ… ç¡®è®¤å½•å…¥", type="primary"):
                    if cash_amount > 0:
                        # è½¬æ¢ä¸ºå…ƒå¹¶ç¡®å®šç±»å‹
                        amount_yuan = cash_amount * 10000
                        flow_type_db = "outflow" if flow_type == "å‡ºé‡‘" else "inflow"
                        today_date = datetime.now().strftime('%Y-%m-%d')

                        success = db.add_cash_flow(
                            selected_product_name,
                            today_date,
                            flow_type_db,
                            amount_yuan,
                            note
                        )

                        if success:
                            st.success(f"âœ… è®°å½•æˆåŠŸï¼š{flow_type} {cash_amount}ä¸‡å…ƒ")
                            time.sleep(1)  # çŸ­æš‚å»¶è¿Ÿè®©ç”¨æˆ·çœ‹åˆ°æˆåŠŸä¿¡æ¯
                            st.rerun()  # åˆ·æ–°é¡µé¢æ˜¾ç¤ºæœ€æ–°æ•°æ®
                        else:
                            st.error("âŒ è®°å½•å¤±è´¥ï¼Œè¯·é‡è¯•")
                    else:
                        st.warning("âš ï¸ è¯·è¾“å…¥å¤§äº0çš„é‡‘é¢")

            with col_btn2:
                if st.button("ğŸ—‘ï¸ æ¸…é™¤ä»Šæ—¥"):
                    today_date = datetime.now().strftime('%Y-%m-%d')

                    # è·å–ä»Šæ—¥çš„æ‰€æœ‰å‡ºå…¥é‡‘è®°å½•å¹¶åˆ é™¤
                    today_flows = db.get_cash_flows_by_unit(selected_product_name)
                    today_flows = today_flows[today_flows['æ—¥æœŸ'] == today_date]

                    deleted_count = 0
                    for _, flow in today_flows.iterrows():
                        flow_type_db = flow['ç±»å‹']
                        amount = flow['é‡‘é¢']
                        success = db.delete_cash_flow(selected_product_name, today_date, flow_type_db, amount)
                        if success:
                            deleted_count += 1

                    if deleted_count > 0:
                        st.success(f"âœ… å·²æ¸…é™¤ä»Šæ—¥{deleted_count}æ¡è®°å½•")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.info("â„¹ï¸ ä»Šæ—¥æš‚æ— è®°å½•éœ€è¦æ¸…é™¤")

        # å³åˆ—ï¼šæ˜¾ç¤ºå‡ºå…¥é‡‘å†å²
        with col_history:
            st.write("**å‡ºå…¥é‡‘å†å²**")

            try:
                cash_flows = db.get_cash_flows_by_unit(selected_product_name)

                if not cash_flows.empty:
                    # æ ¼å¼åŒ–æ˜¾ç¤º
                    display_df = cash_flows.copy()
                    display_df['é‡‘é¢(ä¸‡å…ƒ)'] = display_df['é‡‘é¢'].apply(lambda x: f"{x / 10000:.1f}")
                    display_df['ç±»å‹'] = display_df['ç±»å‹'].map({
                        "inflow": "ğŸ’° å…¥é‡‘",
                        "outflow": "ğŸ“¤ å‡ºé‡‘"
                    })

                    # æ˜¾ç¤ºæœ€è¿‘10æ¡è®°å½•
                    st.dataframe(
                        display_df[['æ—¥æœŸ', 'ç±»å‹', 'é‡‘é¢(ä¸‡å…ƒ)', 'å¤‡æ³¨']].head(10),
                        use_container_width=True,
                        hide_index=True
                    )

                    # æ˜¾ç¤ºä»Šæ—¥æ±‡æ€»
                    today_date = datetime.now().strftime('%Y-%m-%d')
                    today_flows = cash_flows[cash_flows['æ—¥æœŸ'] == today_date]

                    if not today_flows.empty:
                        today_inflow = today_flows[today_flows['ç±»å‹'] == 'inflow']['é‡‘é¢'].sum()
                        today_outflow = today_flows[today_flows['ç±»å‹'] == 'outflow']['é‡‘é¢'].sum()
                        today_net_flow = today_inflow - today_outflow

                        # åˆ›å»ºä¸‰åˆ—æ˜¾ç¤ºä»Šæ—¥æ±‡æ€»
                        col_in, col_out, col_net = st.columns(3)

                        with col_in:
                            st.metric("ä»Šæ—¥å…¥é‡‘", f"{today_inflow / 10000:.1f}ä¸‡", delta=None)

                        with col_out:
                            st.metric("ä»Šæ—¥å‡ºé‡‘", f"{today_outflow / 10000:.1f}ä¸‡", delta=None)

                        with col_net:
                            net_color = "normal" if today_net_flow >= 0 else "inverse"
                            st.metric(
                                "å‡€æµå…¥",
                                f"{today_net_flow / 10000:.1f}ä¸‡",
                                delta=f"{'æµå…¥' if today_net_flow >= 0 else 'æµå‡º'}",
                                delta_color=net_color
                            )
                    else:
                        st.info("ğŸ“Š ä»Šæ—¥æš‚æ— å‡ºå…¥é‡‘è®°å½•")

                else:
                    st.info("ğŸ“ æš‚æ— å‡ºå…¥é‡‘å†å²è®°å½•")
                    st.caption("æç¤ºï¼šé¦–æ¬¡ä½¿ç”¨è¯·å…ˆå½•å…¥å‡ºå…¥é‡‘ä¿¡æ¯ä»¥è·å¾—å‡†ç¡®çš„æ”¶ç›Šç‡")

            except Exception as e:
                st.error(f"âŒ è·å–å‡ºå…¥é‡‘æ•°æ®å¤±è´¥ï¼š{str(e)}")

def get_latest_asset_files(data_source="å®ç›˜"):
    """è·å–æœ€æ–°çš„èµ„äº§å¯¼å‡ºæ–‡ä»¶"""
    try:
        base_path = DATA_PATHS[data_source]
        if not os.path.exists(base_path):
            return None

        # è·å–æœ€æ–°æ—¥æœŸæ–‡ä»¶å¤¹
        date_folders = [f for f in os.listdir(base_path)
                        if f.isdigit() and len(f) == 8 and os.path.isdir(os.path.join(base_path, f))]

        if not date_folders:
            return None

        latest_date_folder = max(date_folders)
        date_folder_path = os.path.join(base_path, latest_date_folder)

        # æŸ¥æ‰¾èµ„äº§å¯¼å‡ºæ–‡ä»¶
        asset_files = []
        for root, dirs, files in os.walk(date_folder_path):
            for file in files:
                if file.startswith("å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º_") and (file.endswith('.xlsx') or file.endswith('.csv')):
                    asset_files.append(os.path.join(root, file))

        # æ‰¾åˆ°æœ€æ–°æ—¶é—´çš„æ–‡ä»¶
        latest_asset_file = None
        latest_time = None

        for file_path in asset_files:
            filename = os.path.basename(file_path)
            # è§£ææ—¶é—´ï¼šå•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º_20250626-161500
            time_part = filename.replace('å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º_', '').replace('.xlsx', '').replace('.csv', '')
            try:
                file_time = datetime.strptime(time_part, "%Y%m%d-%H%M%S")
                if latest_time is None or file_time > latest_time:
                    latest_time = file_time
                    latest_asset_file = file_path
            except:
                continue

        return latest_asset_file

    except Exception as e:
        print(f"è¯»å–{data_source}èµ„äº§æ–‡ä»¶å¤±è´¥: {e}")
        return None


def read_asset_file(file_path):
    """è¯»å–èµ„äº§å¯¼å‡ºæ–‡ä»¶"""
    try:
        if file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        else:
            df = pd.read_csv(file_path, encoding='utf-8-sig')

        # æŸ¥æ‰¾éœ€è¦çš„åˆ—
        product_col = None
        profit_col = None
        asset_col = None

        for col in df.columns:
            if 'äº§å“åç§°' in col:
                product_col = col
            elif 'å½“æ—¥ç›ˆäº' in col:
                profit_col = col
            elif 'æ€»èµ„äº§' in col:
                asset_col = col

        if not all([product_col, profit_col, asset_col]):
            return pd.DataFrame()

        # æå–éœ€è¦çš„æ•°æ®
        result_df = df[[product_col, profit_col, asset_col]].copy()
        result_df.columns = ['product_name', 'daily_profit', 'total_asset']

        # æ•°æ®ç±»å‹è½¬æ¢
        result_df['daily_profit'] = pd.to_numeric(result_df['daily_profit'], errors='coerce')
        result_df['total_asset'] = pd.to_numeric(result_df['total_asset'], errors='coerce')

        # è®¡ç®—å½“æ—¥æ”¶ç›Šç‡
        result_df['daily_return'] = (result_df['daily_profit'] / result_df['total_asset'] * 100).fillna(0)

        return result_df

    except Exception as e:
        print(f"è¯»å–èµ„äº§æ–‡ä»¶å¤±è´¥: {e}")
        return pd.DataFrame()


def get_product_return_from_holdings(product_name, data_source="å®ç›˜", db=None):
    """ä»èµ„äº§æ–‡ä»¶è·å–äº§å“æ”¶ç›Šç‡ï¼ˆåŒ…å«æœŸè´§ï¼‰- ä¿®æ­£å‡ºå…¥é‡‘è°ƒæ•´é€»è¾‘"""
    try:
        print(f"ğŸ” å¼€å§‹è®¡ç®—æ”¶ç›Šç‡:")
        print(f"  - äº§å“åç§°: {product_name}")
        print(f"  - æ•°æ®æº: {data_source}")

        if product_name == "ç‘å¹¸1å·":
            return calculate_ruixing_return(product_name, db)

        base_path = DATA_PATHS[data_source]

        if not os.path.exists(base_path):
            print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {base_path}")
            return None

        # è·å–æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹å¹¶æ’åº
        all_items = os.listdir(base_path)
        date_folders = [f for f in all_items
                        if f.isdigit() and len(f) == 8 and os.path.isdir(os.path.join(base_path, f))]

        if len(date_folders) < 2:
            print(f"âŒ æ—¥æœŸæ–‡ä»¶å¤¹ä¸è¶³2ä¸ª")
            return None

        date_folders.sort(reverse=True)
        today_folder = date_folders[0]  # å¦‚ï¼š20250708
        yesterday_folder = date_folders[1]  # å¦‚ï¼š20250707

        print(f"  - ä»Šæ—¥: {today_folder}, æ˜¨æ—¥: {yesterday_folder}")

        # è·å–ä»Šå¤©çš„æ€»èµ„äº§ï¼ˆç°è´§+æœŸè´§ï¼‰
        today_assets = get_latest_asset_data_by_folder(base_path, today_folder)
        today_futures = get_latest_futures_data_by_date(today_folder, data_source)
        today_combined = combine_assets_and_futures(today_assets, today_futures)

        # è·å–æ˜¨å¤©çš„æ€»èµ„äº§ï¼ˆç°è´§+æœŸè´§ï¼‰
        yesterday_assets = get_latest_asset_data_by_folder(base_path, yesterday_folder)
        yesterday_futures = get_latest_futures_data_by_date(yesterday_folder, data_source)
        yesterday_combined = combine_assets_and_futures(yesterday_assets, yesterday_futures)

        if today_combined is None or yesterday_combined is None:
            print("âŒ åˆå¹¶æ•°æ®å¤±è´¥")
            return None

        # æŸ¥æ‰¾å…·ä½“äº§å“çš„èµ„äº§
        today_product = today_combined[today_combined['äº§å“åç§°'] == product_name]
        yesterday_product = yesterday_combined[yesterday_combined['äº§å“åç§°'] == product_name]

        if today_product.empty or yesterday_product.empty:
            print(f"âŒ äº§å“åŒ¹é…å¤±è´¥")
            print(f"  - ä»Šæ—¥å¯ç”¨äº§å“: {today_combined['äº§å“åç§°'].tolist()}")
            print(f"  - æ˜¨æ—¥å¯ç”¨äº§å“: {yesterday_combined['äº§å“åç§°'].tolist()}")
            return None

        # è·å–ä»Šæ—¥å’Œæ˜¨æ—¥çš„æ€»èµ„äº§
        today_total_asset = today_product['çœŸå®æ€»èµ„äº§'].iloc[0]
        yesterday_total_asset = yesterday_product['çœŸå®æ€»èµ„äº§'].iloc[0]

        print(f"ğŸ’° èµ„äº§æ•°æ®:")
        print(f"  - ä»Šæ—¥æ€»èµ„äº§: {today_total_asset:,.0f}")
        print(f"  - æ˜¨æ—¥æ€»èµ„äº§: {yesterday_total_asset:,.0f}")

        # è·å–ä»Šæ—¥å‡ºå…¥é‡‘æ•°æ®
        total_outflow = 0  # å‡ºé‡‘æ€»é¢
        total_inflow = 0  # å…¥é‡‘æ€»é¢

        if db is not None:
            today_date_str = f"{today_folder[:4]}-{today_folder[4:6]}-{today_folder[6:8]}"
            print(f"ğŸ“… æŸ¥è¯¢å‡ºå…¥é‡‘æ—¥æœŸ: {today_date_str}")

            try:
                # è·å–ä»Šæ—¥çš„æ‰€æœ‰å‡ºå…¥é‡‘è®°å½•
                cash_flows = db.get_cash_flows_by_unit(product_name)
                today_flows = cash_flows[cash_flows['æ—¥æœŸ'] == today_date_str]

                if not today_flows.empty:
                    total_inflow = today_flows[today_flows['ç±»å‹'] == 'inflow']['é‡‘é¢'].sum()
                    total_outflow = today_flows[today_flows['ç±»å‹'] == 'outflow']['é‡‘é¢'].sum()

                print(f"ğŸ’¸ å‡ºå…¥é‡‘æ•°æ®:")
                print(f"  - ä»Šæ—¥å…¥é‡‘: {total_inflow:,.0f}")
                print(f"  - ä»Šæ—¥å‡ºé‡‘: {total_outflow:,.0f}")

            except Exception as e:
                print(f"âŒ è·å–å‡ºå…¥é‡‘å¤±è´¥: {e}")
                total_inflow = 0
                total_outflow = 0
        else:
            print("âš ï¸ æœªæä¾›DBå¯¹è±¡ï¼Œè·³è¿‡å‡ºå…¥é‡‘è°ƒæ•´")

        # âœ… ä¿®æ­£çš„æ”¶ç›Šç‡è®¡ç®—é€»è¾‘
        # åŸå§‹æ”¶ç›Š = ä»Šæ—¥æ€»èµ„äº§ - æ˜¨æ—¥æ€»èµ„äº§
        raw_return = today_total_asset - yesterday_total_asset

        # è°ƒæ•´é€»è¾‘ï¼š
        # å¦‚æœä»Šå¤©å‡ºé‡‘ï¼Œè¯´æ˜èµ„äº§å‡å°‘ä¸æ˜¯å› ä¸ºäºæŸï¼Œéœ€è¦åŠ å›æ¥
        # å¦‚æœä»Šå¤©å…¥é‡‘ï¼Œè¯´æ˜èµ„äº§å¢åŠ ä¸æ˜¯å› ä¸ºç›ˆåˆ©ï¼Œéœ€è¦å‡å»
        # è°ƒæ•´åæ”¶ç›Š = åŸå§‹æ”¶ç›Š + å‡ºé‡‘ - å…¥é‡‘
        adjusted_return = raw_return + total_outflow - total_inflow

        print(f"ğŸ“ˆ æ”¶ç›Šç‡è®¡ç®—:")
        print(f"  - åŸå§‹æ”¶ç›Š: {raw_return:,.0f}")
        print(f"  - å‡ºé‡‘è°ƒæ•´: +{total_outflow:,.0f}")
        print(f"  - å…¥é‡‘è°ƒæ•´: -{total_inflow:,.0f}")
        print(f"  - è°ƒæ•´åæ”¶ç›Š: {adjusted_return:,.0f}")

        if yesterday_total_asset <= 0:
            print("âŒ æ˜¨æ—¥æ€»èµ„äº§ä¸º0æˆ–è´Ÿæ•°")
            return None

        return_rate = (adjusted_return / (yesterday_total_asset - total_outflow + total_inflow)) * 100
        print(f"  - æœ€ç»ˆæ”¶ç›Šç‡: {return_rate:.4f}%")

        return return_rate

    except Exception as e:
        print(f"âŒ è®¡ç®—æ”¶ç›Šç‡å¼‚å¸¸: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None


def get_latest_asset_data_by_folder(base_path, date_folder,data_source="å®ç›˜"):
    """è·å–æŒ‡å®šæ—¥æœŸæ–‡ä»¶å¤¹ä¸­æœ€æ–°çš„èµ„äº§æ•°æ®"""
    try:
        folder_path = os.path.join(base_path, date_folder)
        asset_files = []

        for root, dirs, files in os.walk(folder_path):
            for file in files:
                # æ ¹æ®æ•°æ®æºåŒ¹é…ä¸åŒçš„æ–‡ä»¶å
                file_matched = False
                time_part = ""

                if data_source == "ä»¿çœŸ":
                    # ä»¿çœŸæ”¯æŒä¸¤ç§èµ„äº§æ–‡ä»¶æ ¼å¼
                    if file.startswith("å•å…ƒè´¦æˆ·å±‚èµ„äº§èµ„äº§å¯¼å‡º") and file.endswith('.xlsx'):
                        time_part = file.replace('å•å…ƒè´¦æˆ·å±‚èµ„äº§èµ„äº§å¯¼å‡º_', '').replace('.xlsx', '')
                        file_matched = True
                    elif file.startswith("å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º") and file.endswith('.xlsx'):
                        time_part = file.replace('å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º_', '').replace('.xlsx', '')
                        file_matched = True
                else:
                    # å®ç›˜ä¿æŒåŸæ ¼å¼
                    if file.startswith("å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º") and file.endswith('.xlsx'):
                        time_part = file.replace('å•å…ƒèµ„äº§è´¦æˆ·èµ„äº§å¯¼å‡º_', '').replace('.xlsx', '')
                        file_matched = True

                if file_matched:
                    file_path = os.path.join(root, file)
                    try:
                        timestamp = datetime.strptime(time_part, "%Y%m%d-%H%M%S")
                        asset_files.append({'file_path': file_path, 'timestamp': timestamp})
                    except:
                        continue

        if not asset_files:
            return None

        # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(asset_files, key=lambda x: x['timestamp'])

        # è¯»å–æ•°æ®
        from components.product_returns import read_total_assets_from_holding_file
        return read_total_assets_from_holding_file(latest_file['file_path'])

    except:
        return None


def get_latest_futures_data_by_date(target_date, data_source="å®ç›˜"):
    """è·å–æŒ‡å®šæ—¥æœŸçš„æœ€æ–°æœŸè´§æ•°æ®"""
    try:
        # ä»¿çœŸä¸éœ€è¦æœŸè´§æ•°æ®ï¼Œç›´æ¥è¿”å›None
        if data_source == "ä»¿çœŸ":
            return None

        futures_dir = r"C:\shared_data\æœŸè´§"

        if not os.path.exists(futures_dir):
            return None

        # è§£ææ‰€æœ‰æœŸè´§æ–‡ä»¶
        all_futures_files = []

        for file in os.listdir(futures_dir):
            if file.startswith("æœŸè´§èµ„äº§å¯¼å‡º_") and file.endswith('.xls'):
                try:
                    # è§£ææ–‡ä»¶åä¸­çš„æ—¥æœŸå’Œæ—¶é—´
                    time_part = file.replace('æœŸè´§èµ„äº§å¯¼å‡º_', '').replace('.xls', '')
                    timestamp = datetime.strptime(time_part, '%Y%m%d-%H%M%S')
                    file_date = timestamp.strftime('%Y%m%d')

                    all_futures_files.append({
                        'file_path': os.path.join(futures_dir, file),
                        'timestamp': timestamp,
                        'file_date': file_date,
                        'filename': file
                    })
                except:
                    continue

        if not all_futures_files:
            return None

        if target_date == max([f['file_date'] for f in all_futures_files]):
            # å¦‚æœæ˜¯æœ€æ–°æ—¥æœŸï¼Œé€‰æ‹©æ‰€æœ‰æ–‡ä»¶ä¸­æ—¶é—´æœ€æ–°çš„
            latest_file = max(all_futures_files, key=lambda x: x['timestamp'])
        else:
            # å¦‚æœæ˜¯å†å²æ—¥æœŸï¼Œé€‰æ‹©è¯¥æ—¥æœŸæœ€æ™šçš„æ–‡ä»¶
            target_date_files = [f for f in all_futures_files if f['file_date'] == target_date]

            if not target_date_files:
                # å¦‚æœä»Šå¤©æ²¡æœ‰æœŸè´§æ–‡ä»¶ï¼Œç”¨æœ€æ–°çš„æœŸè´§æ–‡ä»¶
                latest_file = max(all_futures_files, key=lambda x: x['timestamp'])
            else:
                latest_file = max(target_date_files, key=lambda x: x['timestamp'])

        # è¯»å–æ•°æ®
        from components.product_returns import read_futures_assets_from_file
        return read_futures_assets_from_file(latest_file['file_path'])

    except Exception as e:
        return None

# åœ¨ realtime_heatmap.py ä¸­æ·»åŠ å‡ºå…¥é‡‘è·å–åŠŸèƒ½
def get_cash_flow_for_date(unit_name, date, db):
    """è·å–æŒ‡å®šå•å…ƒå’Œæ—¥æœŸçš„å‡€å‡ºå…¥é‡‘"""
    return db.get_cash_flow_by_date(unit_name, date)


def get_product_return_with_cash_flow_adjustment(product_name, data_source="å®ç›˜", db=None):
    """è®¡ç®—è°ƒæ•´å‡ºå…¥é‡‘åçš„æ”¶ç›Šç‡"""
    # 1. è·å–ä»Šæ—¥å’Œæ˜¨æ—¥çš„æ€»èµ„äº§ï¼ˆè‚¡ç¥¨+æœŸè´§ï¼‰
    today_total_asset = get_today_total_asset(product_name, data_source)
    yesterday_total_asset = get_yesterday_total_asset(product_name, data_source)

    # 2. è·å–ä»Šæ—¥å‡€å‡ºå…¥é‡‘
    today_date = datetime.now().strftime('%Y%m%d')
    net_cash_flow = db.get_cash_flow_by_date(product_name, today_date) if db else 0

    # 3. è®¡ç®—è°ƒæ•´åæ”¶ç›Š
    adjusted_return = today_total_asset - yesterday_total_asset + net_cash_flow

    # 4. è®¡ç®—æ”¶ç›Šç‡
    if yesterday_total_asset > 0:
        return_rate = (adjusted_return / yesterday_total_asset) * 100
    else:
        return_rate = 0

    return return_rate


def calculate_ruixing_return(product_name, db=None):
    """
    ç‘å¹¸1å·ä¸“ç”¨æ”¶ç›Šç‡è®¡ç®—å‡½æ•°ï¼ˆåŒ…å«æœŸè´§ï¼‰
    """
    try:
        print(f"ğŸ¯ å¼€å§‹è®¡ç®—ç‘å¹¸1å·æ”¶ç›Šç‡ï¼ˆåŒ…å«æœŸè´§ï¼‰...")

        # å¯¼å…¥ç‘å¹¸1å·æ•°æ®è¯»å–å™¨
        from .ruixing_data_reader import (
            get_current_trading_date,
            get_previous_trading_date,
            get_ruixing_total_assets_with_futures
        )

        # è·å–äº¤æ˜“æ—¥
        today_trading_date = get_current_trading_date()
        if not today_trading_date:
            print("âŒ æ— æ³•ç¡®å®šå½“å‰äº¤æ˜“æ—¥")
            return None

        yesterday_trading_date = get_previous_trading_date(today_trading_date)
        if not yesterday_trading_date:
            print("âŒ æ— æ³•ç¡®å®šå‰ä¸€äº¤æ˜“æ—¥")
            return None

        # ğŸ¯ è·å–æ€»èµ„äº§ï¼ˆç°è´§+æœŸè´§ï¼‰ï¼Œä¼ å…¥æœŸè´§æ•°æ®è¯»å–å‡½æ•°
        today_total_asset, yesterday_total_asset = get_ruixing_total_assets_with_futures(
            today_trading_date,
            yesterday_trading_date,
            get_latest_futures_data_by_date  # ä½¿ç”¨ç°æœ‰çš„æœŸè´§æ•°æ®è¯»å–å‡½æ•°
        )

        if today_total_asset is None or yesterday_total_asset is None:
            print("âŒ æ— æ³•è·å–ç‘å¹¸1å·æ€»èµ„äº§æ•°æ®")
            return None

        # è·å–ä»Šæ—¥å‡ºå…¥é‡‘æ•°æ®ï¼ˆä¸å…¶ä»–äº§å“é€»è¾‘ç›¸åŒï¼‰
        total_outflow = 0
        total_inflow = 0

        if db is not None:
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨å®é™…çš„ä»Šå¤©æ—¥æœŸæ¥æŸ¥è¯¢å‡ºå…¥é‡‘ï¼Œè€Œä¸æ˜¯äº¤æ˜“æ—¥
            # å› ä¸ºå‡ºå…¥é‡‘å¯èƒ½åœ¨éäº¤æ˜“æ—¥å‘ç”Ÿ
            today_date = datetime.now().strftime('%Y-%m-%d')
            print(f"ğŸ“… æŸ¥è¯¢å‡ºå…¥é‡‘æ—¥æœŸ: {today_date}")

            try:
                cash_flows = db.get_cash_flows_by_unit(product_name)
                today_flows = cash_flows[cash_flows['æ—¥æœŸ'] == today_date]

                if not today_flows.empty:
                    total_inflow = today_flows[today_flows['ç±»å‹'] == 'inflow']['é‡‘é¢'].sum()
                    total_outflow = today_flows[today_flows['ç±»å‹'] == 'outflow']['é‡‘é¢'].sum()

                print(f"ğŸ’¸ å‡ºå…¥é‡‘æ•°æ®:")
                print(f"  - ä»Šæ—¥å…¥é‡‘: {total_inflow:,.0f}")
                print(f"  - ä»Šæ—¥å‡ºé‡‘: {total_outflow:,.0f}")

            except Exception as e:
                print(f"âŒ è·å–å‡ºå…¥é‡‘å¤±è´¥: {e}")
                total_inflow = 0
                total_outflow = 0
        else:
            print("âš ï¸ æœªæä¾›DBå¯¹è±¡ï¼Œè·³è¿‡å‡ºå…¥é‡‘è°ƒæ•´")

        # æ”¶ç›Šç‡è®¡ç®—é€»è¾‘ï¼ˆä¸å…¶ä»–äº§å“ç›¸åŒï¼‰
        raw_return = today_total_asset - yesterday_total_asset
        adjusted_return = raw_return + total_outflow - total_inflow

        print(f"ğŸ“ˆ æ”¶ç›Šç‡è®¡ç®—:")
        print(f"  - åŸå§‹æ”¶ç›Š: {raw_return:,.0f}")
        print(f"  - å‡ºé‡‘è°ƒæ•´: +{total_outflow:,.0f}")
        print(f"  - å…¥é‡‘è°ƒæ•´: -{total_inflow:,.0f}")
        print(f"  - è°ƒæ•´åæ”¶ç›Š: {adjusted_return:,.0f}")

        if yesterday_total_asset <= 0:
            print("âŒ å‰ä¸€äº¤æ˜“æ—¥æ€»èµ„äº§ä¸º0æˆ–è´Ÿæ•°")
            return None

        return_rate = (adjusted_return / yesterday_total_asset) * 100
        print(f"  - æœ€ç»ˆæ”¶ç›Šç‡: {return_rate:.4f}%")

        return return_rate

    except Exception as e:
        print(f"âŒ è®¡ç®—ç‘å¹¸1å·æ”¶ç›Šç‡å¼‚å¸¸: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None